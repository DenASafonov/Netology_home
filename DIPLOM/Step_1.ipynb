{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('big_table.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drug_cod</th>\n",
       "      <th>drug_x</th>\n",
       "      <th>provider_code</th>\n",
       "      <th>provider_drug_cod</th>\n",
       "      <th>code</th>\n",
       "      <th>drug_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>9953</td>\n",
       "      <td>Ацетилсалициловая к-та 500мг №10 тб</td>\n",
       "      <td>0000000000000000000013561</td>\n",
       "      <td>5163</td>\n",
       "      <td>13561</td>\n",
       "      <td>Ацетилсалициловая к-та таб 0,5 г №10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>10604</td>\n",
       "      <td>Сульфокамфокаин 100мг/мл 2мл №10 амп р-р д/ин</td>\n",
       "      <td>0000000000000000000010250</td>\n",
       "      <td>5163</td>\n",
       "      <td>10250</td>\n",
       "      <td>Сульфокамфокаин амп 2 мл №10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>11805</td>\n",
       "      <td>Пирацетам 1200мг №20 тб пл/о</td>\n",
       "      <td>0000000000000000000017469</td>\n",
       "      <td>5163</td>\n",
       "      <td>17469</td>\n",
       "      <td>Пирацетам таб 1200 мг № 20 п/о</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>3941</td>\n",
       "      <td>Торвакард 20мг №30 тб пл/о</td>\n",
       "      <td>0000000000000000000017256</td>\n",
       "      <td>5163</td>\n",
       "      <td>17256</td>\n",
       "      <td>Торвакард 0,02 №30 таб. п\\о</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>6214</td>\n",
       "      <td>Фенистил гель 0.1% 50г (тубы)</td>\n",
       "      <td>0000000000000000000015263</td>\n",
       "      <td>5163</td>\n",
       "      <td>15263</td>\n",
       "      <td>Фенистил  0,1% гель 50 г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>5111</td>\n",
       "      <td>Бетасерк 24мг №20 тб</td>\n",
       "      <td>0000000000000000000014629</td>\n",
       "      <td>5163</td>\n",
       "      <td>14629</td>\n",
       "      <td>Бетасерк таб 24 мг №20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>5132</td>\n",
       "      <td>Дибазол - УБФ 20мг №10 тб</td>\n",
       "      <td>0000000000000000000008789</td>\n",
       "      <td>5163</td>\n",
       "      <td>8789</td>\n",
       "      <td>Дибазол таб 20 мг №10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>6229</td>\n",
       "      <td>Клотримазол 100мг №6 тб ваг</td>\n",
       "      <td>0000000000000000000010395</td>\n",
       "      <td>5163</td>\n",
       "      <td>10395</td>\n",
       "      <td>Клотримазол таб ваг 100 мг №6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>4145</td>\n",
       "      <td>Мидокалм Рихтер 100мг+2,5мг/мл 1мл №5 амп р-р...</td>\n",
       "      <td>0000000000000000000014400</td>\n",
       "      <td>5163</td>\n",
       "      <td>14400</td>\n",
       "      <td>Мидокалм-Рихтер  амп 100 мг+2,5 мг/мл 1 мл №5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>6191</td>\n",
       "      <td>Гевискон форте (мята) 150мл №1 сусп фл</td>\n",
       "      <td>0000000000000000000018330</td>\n",
       "      <td>5163</td>\n",
       "      <td>18330</td>\n",
       "      <td>Гевискон форте сусп фл 150 мл мятный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  drug_cod                                             drug_x  \\\n",
       "25          25      9953                Ацетилсалициловая к-та 500мг №10 тб   \n",
       "26          26     10604      Сульфокамфокаин 100мг/мл 2мл №10 амп р-р д/ин   \n",
       "27          27     11805                       Пирацетам 1200мг №20 тб пл/о   \n",
       "28          28      3941                         Торвакард 20мг №30 тб пл/о   \n",
       "29          29      6214                      Фенистил гель 0.1% 50г (тубы)   \n",
       "30          30      5111                               Бетасерк 24мг №20 тб   \n",
       "31          31      5132                          Дибазол - УБФ 20мг №10 тб   \n",
       "32          32      6229                        Клотримазол 100мг №6 тб ваг   \n",
       "33          33      4145   Мидокалм Рихтер 100мг+2,5мг/мл 1мл №5 амп р-р...   \n",
       "34          34      6191             Гевискон форте (мята) 150мл №1 сусп фл   \n",
       "\n",
       "                provider_code  provider_drug_cod   code  \\\n",
       "25  0000000000000000000013561               5163  13561   \n",
       "26  0000000000000000000010250               5163  10250   \n",
       "27  0000000000000000000017469               5163  17469   \n",
       "28  0000000000000000000017256               5163  17256   \n",
       "29  0000000000000000000015263               5163  15263   \n",
       "30  0000000000000000000014629               5163  14629   \n",
       "31  0000000000000000000008789               5163   8789   \n",
       "32  0000000000000000000010395               5163  10395   \n",
       "33  0000000000000000000014400               5163  14400   \n",
       "34  0000000000000000000018330               5163  18330   \n",
       "\n",
       "                                           drug_y  \n",
       "25           Ацетилсалициловая к-та таб 0,5 г №10  \n",
       "26                   Сульфокамфокаин амп 2 мл №10  \n",
       "27                 Пирацетам таб 1200 мг № 20 п/о  \n",
       "28                    Торвакард 0,02 №30 таб. п\\о  \n",
       "29                       Фенистил  0,1% гель 50 г  \n",
       "30                         Бетасерк таб 24 мг №20  \n",
       "31                          Дибазол таб 20 мг №10  \n",
       "32                  Клотримазол таб ваг 100 мг №6  \n",
       "33  Мидокалм-Рихтер  амп 100 мг+2,5 мг/мл 1 мл №5  \n",
       "34           Гевискон форте сусп фл 150 мл мятный  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[25:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20206"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Parma_Sentence = data.drug_x.tolist()\n",
    "Other_Sentence = data.drug_y.tolist()\n",
    "display(len(Parma_Sentence))\n",
    "display(len(Other_Sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Пентоксифиллин 100мг №60 тб п/о кшчр ',\n",
       " ' Валериана Форте 40мг №50 тб пл/о',\n",
       " ' Луцетам 200мг/мл 5мл №10 р-р д/в/м и в/в введения',\n",
       " ' Амитриптилин 25мг №50 тб',\n",
       " ' Брусники листья №20 1,5г ф/п',\n",
       " ' Тест-полоски  Аккучек Перформа №50 ',\n",
       " ' Дексалгин 25мг №10 тб пл/о ',\n",
       " ' Гастал №30 тб д/расс',\n",
       " ' Гастал №30 тб д/расс',\n",
       " ' Белогент 15г №1 крем для нар прим туба']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Пентоксифиллин таб.п/к/о 0,1 №60 Фармпроект',\n",
       " 'Валериана форте таб. п.о 40мг №50  ',\n",
       " 'Луцетам р-р в/в и в/м 200мг/мл 5мл №10  ',\n",
       " 'Амитриптилин таб. 25мг №50  ',\n",
       " 'Брусника листья 1,5г №20  ',\n",
       " 'Акку-чек перформа тест-полоски д/глюкометра №50  ',\n",
       " 'Дексалгин таб. п.о 25мг №10  ',\n",
       " 'Гастал таб. д/рассас №30  ',\n",
       " 'Гастал таб. д/рассас №30  ',\n",
       " 'Белогент крем 15г  ']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Parma_Sentence[1225:1235],Other_Sentence[1225:1235])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PM_chars = set()\n",
    "for drug_line in Parma_Sentence:\n",
    "    for ch in drug_line:\n",
    "        if (ch not in PM_chars):\n",
    "            PM_chars.add(ch)\n",
    "PM_chars = sorted(list(PM_chars))    \n",
    "PM_chars = set(PM_chars)\n",
    "display(len(PM_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Other_chars = set()\n",
    "display(type(Other_chars))\n",
    "for drug_line in Other_Sentence:\n",
    "    for ch in drug_line:\n",
    "        if (ch not in Other_chars):\n",
    "            Other_chars.add(ch)\n",
    "Other_chars = sorted(list(Other_chars))\n",
    "Other_chars = set(Other_chars)\n",
    "display(len(Other_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(PM_chars, Other_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Сравнение словарей:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Нет в словаре ПМ:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'#', '=', '@', 'J', '\\\\', 'j', 'z', '\\xa0', 'Щ', 'Ъ', 'Ы', 'Ь', '–'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Нет во внешнем словаре:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'&', '<', '>'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Дилемма - добавлять ли во внешние словари символы ПМ? Они же могут там рано или поздно появиться.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'А, давайте-ка добавим!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Проверкочка:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Количество симовлов, которых нет во внешнем словаре:0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Сравнение словарей:')\n",
    "display('Нет в словаре ПМ:')\n",
    "display(Other_chars - PM_chars)\n",
    "display('Нет во внешнем словаре:')\n",
    "display(type(PM_chars))\n",
    "display(type(Other_chars))\n",
    "delta = PM_chars - Other_chars\n",
    "display(delta)\n",
    "display('Дилемма - добавлять ли во внешние словари символы ПМ? Они же могут там рано или поздно появиться.')\n",
    "display('А, давайте-ка добавим!')\n",
    "for ch in delta:\n",
    "    Other_chars.add(ch)\n",
    "display('Проверкочка:')\n",
    "delta = PM_chars - Other_chars\n",
    "display(\"Количество симовлов, которых нет во внешнем словаре:\" + str(len(delta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PM_index_to_char_dict = {}\n",
    "PM_char_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(PM_chars):\n",
    "    PM_index_to_char_dict[k] = v\n",
    "    PM_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "Other_index_to_char_dict = {}\n",
    "Other_char_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(Other_chars):\n",
    "    Other_index_to_char_dict[k] = v\n",
    "    Other_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_PM_sent = max([len(line) for line in Parma_Sentence])\n",
    "max_len_Other_sent = max([len(line) for line in Other_Sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(max_len_PM_sent)\n",
    "display(max_len_Other_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 1000\n",
    "tokenized_Other_sentences = np.zeros(shape = (nb_samples,max_len_Other_sent,len(Other_chars)), dtype='float32')\n",
    "tokenized_PM_sentences = np.zeros(shape = (nb_samples,max_len_PM_sent,len(PM_chars)), dtype='float32')\n",
    "target_data = np.zeros((nb_samples, max_len_PM_sent, len(PM_chars)),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_samples):\n",
    "    for k,ch in enumerate(Other_Sentence[i]):\n",
    "        tokenized_Other_sentences[i,k,Other_char_to_index_dict[ch]] = 1\n",
    "        \n",
    "    for k,ch in enumerate(Parma_Sentence[i]):\n",
    "        tokenized_PM_sentences[i,k,PM_char_to_index_dict[ch]] = 1\n",
    "\n",
    "        # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "        if k > 0:\n",
    "            target_data[i,k-1,PM_char_to_index_dict[ch]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(None,len(Other_chars)))\n",
    "encoder_LSTM = LSTM(256,return_state = True)\n",
    "encoder_outputs, encoder_h, encoder_c = encoder_LSTM (encoder_input)\n",
    "encoder_states = [encoder_h, encoder_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None,len(PM_chars)))\n",
    "decoder_LSTM = LSTM(256,return_sequences=True, return_state = True)\n",
    "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(PM_chars),activation='softmax')\n",
    "decoder_out = decoder_dense (decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 1.4207 - val_loss: 1.1656\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 1.0714 - val_loss: 1.1259\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 1.0485 - val_loss: 1.1135\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 1.0364 - val_loss: 1.0986\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 1.0222 - val_loss: 1.1008\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 1.0179 - val_loss: 1.0909\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 1.0109 - val_loss: 1.0704\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9946 - val_loss: 1.0779\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9932 - val_loss: 1.0636\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9864 - val_loss: 1.0491\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.9764 - val_loss: 1.0557\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.9768 - val_loss: 1.0503\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.9695 - val_loss: 1.0489\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9664 - val_loss: 1.0238\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.9569 - val_loss: 1.0236\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.9489 - val_loss: 1.0166\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9509 - val_loss: 1.0110\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9359 - val_loss: 1.0065\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9327 - val_loss: 0.9836\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9139 - val_loss: 0.9838\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.9141 - val_loss: 0.9702\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.8940 - val_loss: 0.9541\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.8839 - val_loss: 0.9559\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8718 - val_loss: 0.9336\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.8559 - val_loss: 0.9205\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.8456 - val_loss: 0.9275\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.8461 - val_loss: 0.9185\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8305 - val_loss: 0.9017\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8151 - val_loss: 0.8735\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.8165 - val_loss: 0.8700\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.7989 - val_loss: 0.8680\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.7914 - val_loss: 0.8548\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.7915 - val_loss: 0.8464\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.7655 - val_loss: 0.8374\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7563 - val_loss: 0.8303\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.7577 - val_loss: 0.8264\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7432 - val_loss: 0.8091\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7358 - val_loss: 0.8111\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7282 - val_loss: 0.7873\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.7212 - val_loss: 0.7891\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.7085 - val_loss: 0.7836\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.7096 - val_loss: 0.7710\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.6914 - val_loss: 0.7674\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.6923 - val_loss: 0.7602\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.6789 - val_loss: 0.7470\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.6754 - val_loss: 0.7477\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6689 - val_loss: 0.7340\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.6639 - val_loss: 0.7318\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.6572 - val_loss: 0.7232\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.6466 - val_loss: 0.7168\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.6443 - val_loss: 0.7128\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.6348 - val_loss: 0.7074\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.6329 - val_loss: 0.7028\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 19s 24ms/step - loss: 0.6295 - val_loss: 0.7125\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6255 - val_loss: 0.6858\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6173 - val_loss: 0.6865\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6078 - val_loss: 0.6846\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.6076 - val_loss: 0.6741\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5986 - val_loss: 0.6843\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.5956 - val_loss: 0.6617\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.5912 - val_loss: 0.6669\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.5906 - val_loss: 0.6588\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.5858 - val_loss: 0.6571\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 22s 27ms/step - loss: 0.5768 - val_loss: 0.6493\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.5728 - val_loss: 0.6475\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.5688 - val_loss: 0.6371\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 19s 24ms/step - loss: 0.5647 - val_loss: 0.6340\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.5584 - val_loss: 0.6310\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 16s 21ms/step - loss: 0.5602 - val_loss: 0.6304\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5519 - val_loss: 0.6268\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.5490 - val_loss: 0.6254\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 19s 24ms/step - loss: 0.5476 - val_loss: 0.6298\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.5396 - val_loss: 0.6232\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.5419 - val_loss: 0.6101\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5320 - val_loss: 0.6159\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5326 - val_loss: 0.6154\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.5292 - val_loss: 0.6046\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.5252 - val_loss: 0.5971\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5206 - val_loss: 0.5977\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5147 - val_loss: 0.5990\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.5145 - val_loss: 0.5946\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5162 - val_loss: 0.5929\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.5070 - val_loss: 0.5922\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5076 - val_loss: 0.5891\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5017 - val_loss: 0.5789\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.4955 - val_loss: 0.5781\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.4963 - val_loss: 0.5828\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 15s 19ms/step - loss: 0.4938 - val_loss: 0.5715\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.4895 - val_loss: 0.5786\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.4894 - val_loss: 0.5677\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.4839 - val_loss: 0.5677\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.4793 - val_loss: 0.5670\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.4800 - val_loss: 0.5647\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.4723 - val_loss: 0.5668\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 16s 21ms/step - loss: 0.4773 - val_loss: 0.5559\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.4649 - val_loss: 0.5554\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.4657 - val_loss: 0.5607\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.4643 - val_loss: 0.5505\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.4650 - val_loss: 0.5561\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.4555 - val_loss: 0.5520\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fddf7bd1fd0>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit(x=[tokenized_Other_sentences,tokenized_PM_sentences], \n",
    "          y=target_data,\n",
    "          batch_size=164,\n",
    "          epochs=100,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, len(PM_chars)))\n",
    "    target_seq[0, 0,PM_char_to_index_dict[' ']] = 1\n",
    "    \n",
    "    translated_sent = ''\n",
    "    stop_condition = False\n",
    "    \n",
    "    while not stop_condition:\n",
    "        \n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        \n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_PM_char = PM_index_to_char_dict[max_val_index]\n",
    "        translated_sent += sampled_PM_char\n",
    "        \n",
    "        if ( (sampled_PM_char == '\\n') or (len(translated_sent) > max_len_PM_sent)) :\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(PM_chars)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "        \n",
    "    return translated_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: Имудон таб д/рассас №24\n",
      "Decoded sentence: Амлодипин 10мг №30 тб пл/о пролонг дейст и наруж флиноная плостова д я раз дляниг растл д/ин раран лес\n",
      "-\n",
      "Input sentence: Глаумакс 0,005% 2,5 мл фл-кап гл капли\n",
      "Decoded sentence: Кардинам 50мг №20 тб пл/о пролонг дейст и наруж флинтрастидоз 10мг №1 тубаллиноп десстрий сареднил инт\n",
      "-\n",
      "Input sentence: Эссенциале-форте Н капс 300 мг №30.\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Эссенциале-форте Н капс 300 мг №30.\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Димедрол таб №10\n",
      "Decoded sentence: Амлодипин 10мг №30 тб пл/о пролонг дейст и наруж флиноная плостова д я раз дляниг растл д/ин раран лес\n",
      "-\n",
      "Input sentence: Ибупрофен гель 5% 50г туба\n",
      "Decoded sentence: Амлодипин 10мг №30 тб пл/о пролонг дейст и наруж флиноная плостова д я раз дляниг растл д/ин раран лес\n",
      "-\n",
      "Input sentence: Гевискон сусп фл 300 мл мятный\n",
      "Decoded sentence: Амлодипин 10мг №30 тб пл/о пролонг дейст и наруж флиноная плостова д я раз дляниг растл д/ин раран лес\n",
      "-\n",
      "Input sentence: Нурофен сусп фл 100 мг/5 мл 150 мл (апельсин) для детей\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Нурофен сусп фл 100 мг/5 мл 150 мл (клубничная) для детей\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Нормодипин таб 10 мг №30\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими внутрь инаружн прим фустужн рар для в/в введдиминнасус\n",
      "-\n",
      "Input sentence: Ранитидин таб 150 мг №20 (инд уп)\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Ацетилсалициловая к-та таб 0,5 г №10\n",
      "Decoded sentence: Амлодипин 10мг №30 тб пл/о пролонг дейст и наруж флиноная плостова д я раз дляниг растл д/ин раран лес\n",
      "-\n",
      "Input sentence: Аримидекс таб 1 мг №28 (инд уп)\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими внутрь инаружн прим фустужн рар для в/в введдиминнасус\n",
      "-\n",
      "Input sentence: Церепро капс 400 мг №14\n",
      "Decoded sentence: Кардинат 500мг №20 тб пл/о пролон т дейстиназазоль ваг др-стиназалный вашедеи иг рура для инфазинозовв\n",
      "-\n",
      "Input sentence: Нитроспрей 0,4 мг/доза 200 доз 10 мл (инд уп)\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Фуросемид таб 40 мг №50\n",
      "Decoded sentence: Кардинам 50мг №20 тб пл/о пролонг дейст и наруж флинтрастидоз 10мг №1 тубаллинг десстый (окте) с лем №\n",
      "-\n",
      "Input sentence: Бинт гипсовый 10х300\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/имиг внутрь инаруж флитока д/приема внутрь д/прил с руже д\n",
      "-\n",
      "Input sentence: Альфа-Токоферола ацетат (витамин Е) фл 300 мг/мл 50 мл р-р в масле\n",
      "Decoded sentence: Амлодипин 10мг №30 тб пл/о пролонг дейст и наруж флиноная плостова д я раз дляниг растл д/ин раран лес\n",
      "-\n",
      "Input sentence: Рибоксин таб 200 мг №50 (инд уп)\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Лейкопластырь катушка 3х300 ( инд уп).\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Бисептол таб 480 мг №28\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Пиона настойка фл 25 мл (инд уп)\n",
      "Decoded sentence: Кардинат 500мг №20 тб пл/о пролон т дейстиназазоль ваг др-стиназалный вашедеи иг рура для инфазинозовв\n",
      "-\n",
      "Input sentence: Перчатки смотровые латексные н/стер р. МАЛ (пара)\n",
      "Decoded sentence: Кардинат 500мг №20 тб пл/о пролон т дейстиназазоль ваг дрент газал вый д/инг №1G д/приена внужей (интр\n",
      "-\n",
      "Input sentence: Блоктран таб 50 мг №30\n",
      "Decoded sentence: Кардинат 500мг №20 тб пл/о пролон т дейстиназазоль ваг др-стиназалный вашедеи иг рура для инфазинозовв\n",
      "-\n",
      "Input sentence: Энтерофурил капс 100 мг №30\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Ацетилсалициловая к-та таб 0,5 г №10\n",
      "Decoded sentence: Амлодипин 10мг №30 тб пл/о пролонг дейст и наруж флиноная плостова д я раз дляниг растл д/ин раран лес\n",
      "-\n",
      "Input sentence: Сульфокамфокаин амп 2 мл №10\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Пирацетам таб 1200 мг № 20 п/о\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/ими ваствири интруж  шед покимутура н ражед ил струй  10*1\n",
      "-\n",
      "Input sentence: Торвакард 0,02 №30 таб. п\\о\n",
      "Decoded sentence: Кардинат 500мг №10 тб пл/о прол г тей каш д/имиг внутрь инаруж флитока д/приема внутрь д/прил с руже д\n",
      "-\n",
      "Input sentence: Фенистил  0,1% гель 50 г\n",
      "Decoded sentence: Кардинам 50мг №20 тб пл/о пролонг дейст и наруж флинтрастидоз 10мг №1 тубаллиноп десстрий сареднил инт\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(30):\n",
    "    inp_seq = tokenized_Other_sentences[seq_index:seq_index+1]\n",
    "    translated_sent = decode_seq(inp_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', Other_Sentence[seq_index])\n",
    "    print('Decoded sentence:', translated_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
