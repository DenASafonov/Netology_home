{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('big_table.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drug_cod</th>\n",
       "      <th>drug_x</th>\n",
       "      <th>provider_code</th>\n",
       "      <th>provider_drug_cod</th>\n",
       "      <th>code</th>\n",
       "      <th>drug_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>9953</td>\n",
       "      <td>Ацетилсалициловая к-та 500мг №10 тб</td>\n",
       "      <td>0000000000000000000013561</td>\n",
       "      <td>5163</td>\n",
       "      <td>13561</td>\n",
       "      <td>Ацетилсалициловая к-та таб 0,5 г №10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>10604</td>\n",
       "      <td>Сульфокамфокаин 100мг/мл 2мл №10 амп р-р д/ин</td>\n",
       "      <td>0000000000000000000010250</td>\n",
       "      <td>5163</td>\n",
       "      <td>10250</td>\n",
       "      <td>Сульфокамфокаин амп 2 мл №10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>11805</td>\n",
       "      <td>Пирацетам 1200мг №20 тб пл/о</td>\n",
       "      <td>0000000000000000000017469</td>\n",
       "      <td>5163</td>\n",
       "      <td>17469</td>\n",
       "      <td>Пирацетам таб 1200 мг № 20 п/о</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>3941</td>\n",
       "      <td>Торвакард 20мг №30 тб пл/о</td>\n",
       "      <td>0000000000000000000017256</td>\n",
       "      <td>5163</td>\n",
       "      <td>17256</td>\n",
       "      <td>Торвакард 0,02 №30 таб. п\\о</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>6214</td>\n",
       "      <td>Фенистил гель 0.1% 50г (тубы)</td>\n",
       "      <td>0000000000000000000015263</td>\n",
       "      <td>5163</td>\n",
       "      <td>15263</td>\n",
       "      <td>Фенистил  0,1% гель 50 г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>5111</td>\n",
       "      <td>Бетасерк 24мг №20 тб</td>\n",
       "      <td>0000000000000000000014629</td>\n",
       "      <td>5163</td>\n",
       "      <td>14629</td>\n",
       "      <td>Бетасерк таб 24 мг №20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>5132</td>\n",
       "      <td>Дибазол - УБФ 20мг №10 тб</td>\n",
       "      <td>0000000000000000000008789</td>\n",
       "      <td>5163</td>\n",
       "      <td>8789</td>\n",
       "      <td>Дибазол таб 20 мг №10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>6229</td>\n",
       "      <td>Клотримазол 100мг №6 тб ваг</td>\n",
       "      <td>0000000000000000000010395</td>\n",
       "      <td>5163</td>\n",
       "      <td>10395</td>\n",
       "      <td>Клотримазол таб ваг 100 мг №6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>4145</td>\n",
       "      <td>Мидокалм Рихтер 100мг+2,5мг/мл 1мл №5 амп р-р...</td>\n",
       "      <td>0000000000000000000014400</td>\n",
       "      <td>5163</td>\n",
       "      <td>14400</td>\n",
       "      <td>Мидокалм-Рихтер  амп 100 мг+2,5 мг/мл 1 мл №5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>6191</td>\n",
       "      <td>Гевискон форте (мята) 150мл №1 сусп фл</td>\n",
       "      <td>0000000000000000000018330</td>\n",
       "      <td>5163</td>\n",
       "      <td>18330</td>\n",
       "      <td>Гевискон форте сусп фл 150 мл мятный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  drug_cod                                             drug_x  \\\n",
       "25          25      9953                Ацетилсалициловая к-та 500мг №10 тб   \n",
       "26          26     10604      Сульфокамфокаин 100мг/мл 2мл №10 амп р-р д/ин   \n",
       "27          27     11805                       Пирацетам 1200мг №20 тб пл/о   \n",
       "28          28      3941                         Торвакард 20мг №30 тб пл/о   \n",
       "29          29      6214                      Фенистил гель 0.1% 50г (тубы)   \n",
       "30          30      5111                               Бетасерк 24мг №20 тб   \n",
       "31          31      5132                          Дибазол - УБФ 20мг №10 тб   \n",
       "32          32      6229                        Клотримазол 100мг №6 тб ваг   \n",
       "33          33      4145   Мидокалм Рихтер 100мг+2,5мг/мл 1мл №5 амп р-р...   \n",
       "34          34      6191             Гевискон форте (мята) 150мл №1 сусп фл   \n",
       "\n",
       "                provider_code  provider_drug_cod   code  \\\n",
       "25  0000000000000000000013561               5163  13561   \n",
       "26  0000000000000000000010250               5163  10250   \n",
       "27  0000000000000000000017469               5163  17469   \n",
       "28  0000000000000000000017256               5163  17256   \n",
       "29  0000000000000000000015263               5163  15263   \n",
       "30  0000000000000000000014629               5163  14629   \n",
       "31  0000000000000000000008789               5163   8789   \n",
       "32  0000000000000000000010395               5163  10395   \n",
       "33  0000000000000000000014400               5163  14400   \n",
       "34  0000000000000000000018330               5163  18330   \n",
       "\n",
       "                                           drug_y  \n",
       "25           Ацетилсалициловая к-та таб 0,5 г №10  \n",
       "26                   Сульфокамфокаин амп 2 мл №10  \n",
       "27                 Пирацетам таб 1200 мг № 20 п/о  \n",
       "28                    Торвакард 0,02 №30 таб. п\\о  \n",
       "29                       Фенистил  0,1% гель 50 г  \n",
       "30                         Бетасерк таб 24 мг №20  \n",
       "31                          Дибазол таб 20 мг №10  \n",
       "32                  Клотримазол таб ваг 100 мг №6  \n",
       "33  Мидокалм-Рихтер  амп 100 мг+2,5 мг/мл 1 мл №5  \n",
       "34           Гевискон форте сусп фл 150 мл мятный  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[25:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Parma_Sentence = data.drug_x.tolist()\n",
    "Other_Sentence = data.drug_y.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Ацетилсалициловая к-та 500мг №10 тб',\n",
       " ' Сульфокамфокаин 100мг/мл 2мл №10 амп р-р д/ин',\n",
       " ' Пирацетам 1200мг №20 тб пл/о',\n",
       " ' Торвакард 20мг №30 тб пл/о',\n",
       " ' Фенистил гель 0.1% 50г (тубы)',\n",
       " ' Бетасерк 24мг №20 тб',\n",
       " ' Дибазол - УБФ 20мг №10 тб',\n",
       " ' Клотримазол 100мг №6 тб ваг',\n",
       " ' Мидокалм Рихтер 100мг+2,5мг/мл 1мл №5 амп р-р для в/в и в/м введ',\n",
       " ' Гевискон форте (мята) 150мл №1 сусп фл']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['Ацетилсалициловая к-та таб 0,5 г №10',\n",
       " 'Сульфокамфокаин амп 2 мл №10',\n",
       " 'Пирацетам таб 1200 мг № 20 п/о',\n",
       " 'Торвакард 0,02 №30 таб. п\\\\о',\n",
       " 'Фенистил  0,1% гель 50 г',\n",
       " 'Бетасерк таб 24 мг №20',\n",
       " 'Дибазол таб 20 мг №10',\n",
       " 'Клотримазол таб ваг 100 мг №6',\n",
       " 'Мидокалм-Рихтер  амп 100 мг+2,5 мг/мл 1 мл №5',\n",
       " 'Гевискон форте сусп фл 150 мл мятный']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Parma_Sentence[25:35],Other_Sentence[25:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PM_chars = set()\n",
    "for drug_line in Parma_Sentence:\n",
    "    for ch in drug_line:\n",
    "        if (ch not in PM_chars):\n",
    "            PM_chars.add(ch)\n",
    "PM_chars = sorted(list(PM_chars))    \n",
    "PM_chars = set(PM_chars)\n",
    "display(len(PM_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Other_chars = set()\n",
    "display(type(Other_chars))\n",
    "for drug_line in Other_Sentence:\n",
    "    for ch in drug_line:\n",
    "        if (ch not in Other_chars):\n",
    "            Other_chars.add(ch)\n",
    "Other_chars = sorted(list(Other_chars))\n",
    "Other_chars = set(Other_chars)\n",
    "display(len(Other_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(PM_chars, Other_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Сравнение словарей:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Нет в словаре ПМ:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'#', '=', '@', 'J', '\\\\', 'j', 'z', '\\xa0', 'Щ', 'Ъ', 'Ы', 'Ь', '–'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Нет во внешнем словаре:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'&', '<', '>'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Сравнение словарей:')\n",
    "display('Нет в словаре ПМ:')\n",
    "display(Other_chars - PM_chars)\n",
    "display('Нет во внешнем словаре:')\n",
    "display(type(PM_chars))\n",
    "display(type(Other_chars))\n",
    "delta = PM_chars - Other_chars\n",
    "display(delta)\n",
    "#display('Дилемма - добавлять ли во внешние словари символы ПМ? Они же могут там рано или поздно появиться.')\n",
    "#display('А, давайте-ка добавим!')\n",
    "#for ch in delta:\n",
    "#    Other_chars.add(ch)\n",
    "#display('Проверкочка:')\n",
    "#delta = PM_chars - Other_chars\n",
    "#display(\"Количество симовлов, которых нет во внешнем словаре:\" + str(len(delta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PM_index_to_char_dict = {}\n",
    "PM_char_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(PM_chars):\n",
    "    PM_index_to_char_dict[k] = v\n",
    "    PM_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Other_index_to_char_dict = {}\n",
    "Other_char_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(Other_chars):\n",
    "    Other_index_to_char_dict[k] = v\n",
    "    Other_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_PM_sent = max([len(line) for line in Parma_Sentence])\n",
    "max_len_Other_sent = max([len(line) for line in Other_Sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(max_len_PM_sent)\n",
    "display(max_len_Other_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = 1000\n",
    "tokenized_PM_sentences    = np.zeros(shape = (nb_samples,max_len_PM_sent,   len(PM_chars)),    dtype='float32')\n",
    "tokenized_Other_sentences = np.zeros(shape = (nb_samples,max_len_Other_sent,len(Other_chars)), dtype='float32')\n",
    "target_data = np.zeros((nb_samples, max_len_Other_sent, len(Other_chars)),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_samples):\n",
    "    for k,ch in enumerate(Parma_Sentence[i]):\n",
    "        tokenized_PM_sentences[i,k,PM_char_to_index_dict[ch]] = 1\n",
    "        \n",
    "    for k,ch in enumerate(Other_Sentence[i]):\n",
    "        tokenized_Other_sentences[i,k,Other_char_to_index_dict[ch]] = 1\n",
    "\n",
    "        # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "        if k > 0:\n",
    "            target_data[i,k-1,Other_char_to_index_dict[ch]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(None,len(PM_chars)))\n",
    "encoder_LSTM = LSTM(256,return_state = True)\n",
    "encoder_outputs, encoder_h, encoder_c = encoder_LSTM (encoder_input)\n",
    "encoder_states = [encoder_h, encoder_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None,len(Other_chars)))\n",
    "decoder_LSTM = LSTM(256,return_sequences=True, return_state = True)\n",
    "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(Other_chars),activation='softmax')\n",
    "decoder_out = decoder_dense (decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 1.3852 - val_loss: 1.1647\n",
      "Epoch 2/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9743 - val_loss: 1.0438\n",
      "Epoch 3/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9209 - val_loss: 1.0298\n",
      "Epoch 4/100\n",
      "800/800 [==============================] - 16s 19ms/step - loss: 0.9100 - val_loss: 1.0262\n",
      "Epoch 5/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.9028 - val_loss: 1.0235\n",
      "Epoch 6/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8970 - val_loss: 1.0158\n",
      "Epoch 7/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8895 - val_loss: 1.0186\n",
      "Epoch 8/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.8952 - val_loss: 1.0167\n",
      "Epoch 9/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8847 - val_loss: 0.9862\n",
      "Epoch 10/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8769 - val_loss: 1.0227\n",
      "Epoch 11/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8853 - val_loss: 0.9879\n",
      "Epoch 12/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.8681 - val_loss: 1.0012\n",
      "Epoch 13/100\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.8801 - val_loss: 1.0519\n",
      "Epoch 14/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.8876 - val_loss: 0.9908\n",
      "Epoch 15/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8672 - val_loss: 0.9991\n",
      "Epoch 16/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8651 - val_loss: 0.9860\n",
      "Epoch 17/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8519 - val_loss: 0.9660\n",
      "Epoch 18/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.8526 - val_loss: 0.9889\n",
      "Epoch 19/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.8511 - val_loss: 0.9843\n",
      "Epoch 20/100\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.8364 - val_loss: 1.0073\n",
      "Epoch 21/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8512 - val_loss: 1.0030\n",
      "Epoch 22/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8300 - val_loss: 0.9834\n",
      "Epoch 23/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.8358 - val_loss: 0.9792\n",
      "Epoch 24/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.8267 - val_loss: 0.9688\n",
      "Epoch 25/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.8175 - val_loss: 0.9580\n",
      "Epoch 26/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8092 - val_loss: 0.9612\n",
      "Epoch 27/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7972 - val_loss: 0.9703\n",
      "Epoch 28/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.8049 - val_loss: 0.9397\n",
      "Epoch 29/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7868 - val_loss: 0.9699\n",
      "Epoch 30/100\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.7910 - val_loss: 0.9274\n",
      "Epoch 31/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7672 - val_loss: 0.9121\n",
      "Epoch 32/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7739 - val_loss: 0.9224\n",
      "Epoch 33/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7637 - val_loss: 0.8987\n",
      "Epoch 34/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.7449 - val_loss: 0.9141\n",
      "Epoch 35/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7422 - val_loss: 0.9211\n",
      "Epoch 36/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7396 - val_loss: 0.8873\n",
      "Epoch 37/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7180 - val_loss: 0.8896\n",
      "Epoch 38/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7173 - val_loss: 0.8948\n",
      "Epoch 39/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7188 - val_loss: 0.8584\n",
      "Epoch 40/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6967 - val_loss: 0.8679\n",
      "Epoch 41/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6900 - val_loss: 0.8528\n",
      "Epoch 42/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.7065 - val_loss: 0.8424\n",
      "Epoch 43/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6804 - val_loss: 0.8396\n",
      "Epoch 44/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6728 - val_loss: 0.8452\n",
      "Epoch 45/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6699 - val_loss: 0.8334\n",
      "Epoch 46/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6670 - val_loss: 0.8457\n",
      "Epoch 47/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6643 - val_loss: 0.8156\n",
      "Epoch 48/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6517 - val_loss: 0.8263\n",
      "Epoch 49/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6529 - val_loss: 0.8303\n",
      "Epoch 50/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6463 - val_loss: 0.8308\n",
      "Epoch 51/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6432 - val_loss: 0.8107\n",
      "Epoch 52/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6409 - val_loss: 0.7970\n",
      "Epoch 53/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6240 - val_loss: 0.7940\n",
      "Epoch 54/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6256 - val_loss: 0.8138\n",
      "Epoch 55/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6255 - val_loss: 0.7950\n",
      "Epoch 56/100\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.6153 - val_loss: 0.8116\n",
      "Epoch 57/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6222 - val_loss: 0.7835\n",
      "Epoch 58/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6115 - val_loss: 0.8046\n",
      "Epoch 59/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6081 - val_loss: 0.8012\n",
      "Epoch 60/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6020 - val_loss: 0.7903\n",
      "Epoch 61/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.6000 - val_loss: 0.7872\n",
      "Epoch 62/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.6460 - val_loss: 0.7800\n",
      "Epoch 63/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5876 - val_loss: 0.7988\n",
      "Epoch 64/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5969 - val_loss: 0.7645\n",
      "Epoch 65/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5811 - val_loss: 0.7908\n",
      "Epoch 66/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5888 - val_loss: 0.7685\n",
      "Epoch 67/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5757 - val_loss: 0.7523\n",
      "Epoch 68/100\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.5750 - val_loss: 0.7744\n",
      "Epoch 69/100\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.5722 - val_loss: 0.7708\n",
      "Epoch 70/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5706 - val_loss: 0.7672\n",
      "Epoch 71/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5699 - val_loss: 0.7482\n",
      "Epoch 72/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5574 - val_loss: 0.7710\n",
      "Epoch 73/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5619 - val_loss: 0.7537\n",
      "Epoch 74/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5593 - val_loss: 0.7449\n",
      "Epoch 75/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5496 - val_loss: 0.7617\n",
      "Epoch 76/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5571 - val_loss: 0.7383\n",
      "Epoch 77/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5479 - val_loss: 0.7764\n",
      "Epoch 78/100\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.5601 - val_loss: 0.7226\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5421 - val_loss: 0.7260\n",
      "Epoch 80/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5381 - val_loss: 0.7311\n",
      "Epoch 81/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5441 - val_loss: 0.7246\n",
      "Epoch 82/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5335 - val_loss: 0.7147\n",
      "Epoch 83/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5269 - val_loss: 0.7304\n",
      "Epoch 84/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5323 - val_loss: 0.7116\n",
      "Epoch 85/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5319 - val_loss: 0.7178\n",
      "Epoch 86/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5217 - val_loss: 0.7314\n",
      "Epoch 87/100\n",
      "800/800 [==============================] - 17s 22ms/step - loss: 0.5308 - val_loss: 0.7217\n",
      "Epoch 88/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5507 - val_loss: 0.7343\n",
      "Epoch 89/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5195 - val_loss: 0.7243\n",
      "Epoch 90/100\n",
      "800/800 [==============================] - 23s 28ms/step - loss: 0.5222 - val_loss: 0.7258\n",
      "Epoch 91/100\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.5130 - val_loss: 0.7067\n",
      "Epoch 92/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.5181 - val_loss: 0.7633\n",
      "Epoch 93/100\n",
      "800/800 [==============================] - 22s 28ms/step - loss: 0.5688 - val_loss: 0.7475\n",
      "Epoch 94/100\n",
      "800/800 [==============================] - 18s 23ms/step - loss: 0.5415 - val_loss: 0.7165\n",
      "Epoch 95/100\n",
      "800/800 [==============================] - 16s 20ms/step - loss: 0.5321 - val_loss: 0.7177\n",
      "Epoch 96/100\n",
      "800/800 [==============================] - 17s 21ms/step - loss: 0.5185 - val_loss: 0.7106\n",
      "Epoch 97/100\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.5130 - val_loss: 0.7239\n",
      "Epoch 98/100\n",
      "800/800 [==============================] - 20s 25ms/step - loss: 0.5254 - val_loss: 0.7128\n",
      "Epoch 99/100\n",
      "800/800 [==============================] - 19s 23ms/step - loss: 0.5101 - val_loss: 0.6893\n",
      "Epoch 100/100\n",
      "800/800 [==============================] - 18s 22ms/step - loss: 0.5100 - val_loss: 0.6909\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f593c54dbe0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit(x=[tokenized_PM_sentences,tokenized_Other_sentences], \n",
    "          y=target_data,\n",
    "          batch_size=264,\n",
    "          epochs=100,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, len(Other_chars)))\n",
    "    target_seq[0, 0,Other_char_to_index_dict[' ']] = 1\n",
    "    \n",
    "    translated_sent = ''\n",
    "    stop_condition = False\n",
    "    \n",
    "    while not stop_condition:\n",
    "        \n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        \n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_Other_char = Other_index_to_char_dict[max_val_index]\n",
    "        translated_sent += sampled_Other_char\n",
    "        \n",
    "        if ( (sampled_Other_char == ' ') or (len(translated_sent) > max_len_Other_sent)) :\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(Other_chars)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "        \n",
    "    return translated_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence:  Имудон №24 тб д/расс\n",
      "Decoded sentence: инарин \n",
      "-\n",
      "Input sentence:  Глаумакс 0.005% 2.5мл фл-кап кап глаз\n",
      "Decoded sentence: инарин \n",
      "-\n",
      "Input sentence:  Эссенциале форте Н 300мг №30 капс\n",
      "Decoded sentence: инарин \n",
      "-\n",
      "Input sentence:  Эссенциале форте Н 300мг №30 капс\n",
      "Decoded sentence: инарин \n",
      "-\n",
      "Input sentence:  Димедрол 50мг №10 тб\n",
      "Decoded sentence: инарин \n",
      "-\n",
      "Input sentence:  Ибупрофен 5% 50г гель наруж \n",
      "Decoded sentence: инарин \n",
      "-\n",
      "Input sentence:  Гевискон (мята) 300мл №1 сусп фл\n",
      "Decoded sentence: инарин \n",
      "-\n",
      "Input sentence:  Нурофен 100мг/5мл 150мл сусп д/приема внутрь апельсин\n",
      "Decoded sentence: инарин \n",
      "-\n",
      "Input sentence:  Нурофен 100мг/5мл 150мл сусп д/приема внутрь клубнич \n",
      "Decoded sentence: инарин \n",
      "-\n",
      "Input sentence:  Нормодипин 10мг №30 тб\n",
      "Decoded sentence: инарин \n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(10):\n",
    "    inp_seq = tokenized_PM_sentences[seq_index:seq_index+1]\n",
    "    translated_sent = decode_seq(inp_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', Parma_Sentence[seq_index])\n",
    "    print('Decoded sentence:', translated_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
