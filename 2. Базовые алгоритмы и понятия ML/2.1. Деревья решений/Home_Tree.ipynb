{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightfm\n",
      "  Downloading lightfm-1.14.tar.gz (250kB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from lightfm)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from lightfm)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from lightfm)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->lightfm)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->lightfm)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->lightfm)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->lightfm)\n",
      "Building wheels for collected packages: lightfm\n",
      "  Running setup.py bdist_wheel for lightfm: started\n",
      "  Running setup.py bdist_wheel for lightfm: finished with status 'error'\n",
      "  Complete output from command C:\\ProgramData\\Anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\DenAS\\\\AppData\\\\Local\\\\Temp\\\\pip-build-q3p35lry\\\\lightfm\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" bdist_wheel -d C:\\Users\\DenAS\\AppData\\Local\\Temp\\tmpm6s6d73zpip-wheel- --python-tag cp36:\n",
      "  Compiling without OpenMP support.\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build\\lib.win-amd64-3.6\n",
      "  creating build\\lib.win-amd64-3.6\\lightfm\n",
      "  copying lightfm\\cross_validation.py -> build\\lib.win-amd64-3.6\\lightfm\n",
      "  copying lightfm\\evaluation.py -> build\\lib.win-amd64-3.6\\lightfm\n",
      "  copying lightfm\\lightfm.py -> build\\lib.win-amd64-3.6\\lightfm\n",
      "  copying lightfm\\_lightfm_fast.py -> build\\lib.win-amd64-3.6\\lightfm\n",
      "  copying lightfm\\__init__.py -> build\\lib.win-amd64-3.6\\lightfm\n",
      "  creating build\\lib.win-amd64-3.6\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\movielens.py -> build\\lib.win-amd64-3.6\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\stackexchange.py -> build\\lib.win-amd64-3.6\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\_common.py -> build\\lib.win-amd64-3.6\\lightfm\\datasets\n",
      "  copying lightfm\\datasets\\__init__.py -> build\\lib.win-amd64-3.6\\lightfm\\datasets\n",
      "  copying lightfm\\_lightfm_fast_no_openmp.c -> build\\lib.win-amd64-3.6\\lightfm\n",
      "  copying lightfm\\_lightfm_fast_openmp.c -> build\\lib.win-amd64-3.6\\lightfm\n",
      "  running build_ext\n",
      "  building 'lightfm._lightfm_fast_no_openmp' extension\n",
      "  error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
      "  \n",
      "  ----------------------------------------\n",
      "  Running setup.py clean for lightfm\n",
      "  Complete output from command C:\\ProgramData\\Anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\DenAS\\\\AppData\\\\Local\\\\Temp\\\\pip-build-q3p35lry\\\\lightfm\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" clean --all:\n",
      "  Compiling without OpenMP support.\n",
      "  running clean\n",
      "  error: [WinError 2] Не удается найти указанный файл\n",
      "  \n",
      "  ----------------------------------------\n",
      "Failed to build lightfm\n",
      "Installing collected packages: lightfm\n",
      "  Running setup.py install for lightfm: started\n",
      "    Running setup.py install for lightfm: finished with status 'error'\n",
      "    Complete output from command C:\\ProgramData\\Anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\DenAS\\\\AppData\\\\Local\\\\Temp\\\\pip-build-q3p35lry\\\\lightfm\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\DenAS\\AppData\\Local\\Temp\\pip-r5dw57sk-record\\install-record.txt --single-version-externally-managed --compile:\n",
      "    Compiling without OpenMP support.\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    running build_ext\n",
      "    building 'lightfm._lightfm_fast_no_openmp' extension\n",
      "    error: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
      "    \n",
      "    ----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Failed building wheel for lightfm\n",
      "  Failed cleaning build dir for lightfm\n",
      "Command \"C:\\ProgramData\\Anaconda3\\python.exe -u -c \"import setuptools, tokenize;__file__='C:\\\\Users\\\\DenAS\\\\AppData\\\\Local\\\\Temp\\\\pip-build-q3p35lry\\\\lightfm\\\\setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record C:\\Users\\DenAS\\AppData\\Local\\Temp\\pip-r5dw57sk-record\\install-record.txt --single-version-externally-managed --compile\" failed with error code 1 in C:\\Users\\DenAS\\AppData\\Local\\Temp\\pip-build-q3p35lry\\lightfm\\\n"
     ]
    }
   ],
   "source": [
    "!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('titanic/train.csv')\n",
    "test = pd.read_csv('titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train.Survived\n",
    "train.drop('Survived', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True], dtype=bool)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns == test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['is_test'] = 0\n",
    "test['is_test'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train, test])\n",
    "#df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"isMale\"] = df.Sex.replace({\"male\": 1, \"female\":0})\n",
    "df.drop([\"Sex\", \"Cabin\", \"Ticket\", \"Name\", \"PassengerId\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def age_class(row):\n",
    "    if row['Age'] <= 10:\n",
    "        return 'kind'\n",
    "    elif ( row['Age'] > 10 ) and ( row['Age'] <= 17 ):\n",
    "        return 'teenager'\n",
    "    elif ( row['Age'] > 17 ) and ( row['Age'] <= 21 ):\n",
    "        return 'youth'\n",
    "    elif ( row['Age'] > 21 ) and ( row['Age'] <= 55 ):\n",
    "        return 'mature'    \n",
    "    elif ( row['Age'] > 55 ) and ( row['Age'] <= 75 ):\n",
    "        return 'elderly'\n",
    "    elif ( row['Age'] > 75 ):\n",
    "        return 'old'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['age_class'] = df.apply( age_class, axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_dummies = pd.get_dummies(df, columns=['Pclass', 'Embarked','age_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_dummies.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_dummies.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_dummies[df_dummies.is_test==0].drop('is_test', axis=1)\n",
    "X_test = df_dummies[df_dummies.is_test==1].drop('is_test', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(missing_values='NaN', strategy='mean', axis=0, verbose=0, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Imputer(axis=0, copy=True, missing_values='NaN', strategy='mean', verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputer.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_imputed = imputer.transform(X_train)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_imputed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(X_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_imputed_scaled = scaler.transform(X_train_imputed)\n",
    "X_train_imputed_scaled = pd.DataFrame(X_train_imputed_scaled, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_imputed_scaled.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_imputed_scaled = scaler.transform(imputer.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_imputed_scaled[14:188]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_fin, X_val, y_train_fin, y_val = train_test_split(X_train_imputed_scaled, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cs = 10**np.linspace(-3,1,5)\n",
    "#cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grid = {'C': cs}#, 'max_features': features_num}\n",
    "gridsearch = GridSearchCV(LogisticRegression(), grid, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 240 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': array([  1.00000e-03,   1.00000e-02,   1.00000e-01,   1.00000e+00,\n",
       "         1.00000e+01])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "gridsearch.fit(X_train_fin, y_train_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:747: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.80478, std: 0.05071, params: {'C': 0.01},\n",
       " mean: 0.80478, std: 0.04857, params: {'C': 0.10000000000000001},\n",
       " mean: 0.80478, std: 0.04302, params: {'C': 10.0},\n",
       " mean: 0.80337, std: 0.04563, params: {'C': 1.0},\n",
       " mean: 0.75702, std: 0.04609, params: {'C': 0.001}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(gridsearch.grid_scores_, key = lambda x: -x.mean_validation_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.01}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_C = gridsearch.best_params_[\"C\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression(C=best_C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_fin, y_train_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_val_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.82122905027932958"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_imputed_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7511061 ,  0.2488939 ],\n",
       "       [ 0.55352062,  0.44647938],\n",
       "       [ 0.74172481,  0.25827519],\n",
       "       [ 0.79612608,  0.20387392],\n",
       "       [ 0.49032499,  0.50967501],\n",
       "       [ 0.75515036,  0.24484964],\n",
       "       [ 0.38889586,  0.61110414],\n",
       "       [ 0.67306348,  0.32693652],\n",
       "       [ 0.40647085,  0.59352915],\n",
       "       [ 0.85862841,  0.14137159]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(X_test_imputed_scaled)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = clf.predict(X_test_imputed_scaled)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submussion = 'PassengerId,Survived\\n'\n",
    "submussion += \"\\n\".join([\"{},{}\".format(pid, prediction) for pid, prediction in zip(test.PassengerId, predictions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#submussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('submission.txt', 'w') as file:\n",
    "    file.write(submussion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age                            -0.14\n",
      "SibSp                          -0.15\n",
      "Parch                          -0.03\n",
      "Fare                           0.16\n",
      "isMale                         -0.72\n",
      "Pclass_1                       0.25\n",
      "Pclass_2                       0.08\n",
      "Pclass_3                       -0.27\n",
      "Embarked_C                     0.08\n",
      "Embarked_Q                     0.03\n",
      "Embarked_S                     -0.10\n",
      "age_class_elderly              -0.06\n",
      "age_class_kind                 0.18\n",
      "age_class_mature               0.04\n",
      "age_class_old                  0.07\n",
      "age_class_teenager             0.04\n",
      "age_class_youth                -0.06\n"
     ]
    }
   ],
   "source": [
    "for col, val in zip(X_train.columns, clf.coef_[0]):\n",
    "    print(\"{:30} {:.2f}\".format(col, val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Строим дерево"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_imputed_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "def get_tree_dot_view(clf, feature_names=None, class_names=None):\n",
    "    print(export_graphviz(clf, out_file=None, filled=True, feature_names=feature_names, class_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "clf.fit(X_train_imputed_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\n",
      "node [shape=box, style=\"filled\", color=\"black\"] ;\n",
      "0 [label=\"isMale <= -0.309\\ngini = 0.473\\nsamples = 891\\nvalue = [549, 342]\\nclass = Age\", fillcolor=\"#e5813960\"] ;\n",
      "1 [label=\"Pclass_3 <= -0.103\\ngini = 0.383\\nsamples = 314\\nvalue = [81, 233]\\nclass = SibSp\", fillcolor=\"#399de5a6\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=\"Age <= -2.093\\ngini = 0.1\\nsamples = 170\\nvalue = [9, 161]\\nclass = SibSp\", fillcolor=\"#399de5f1\"] ;\n",
      "1 -> 2 ;\n",
      "3 [label=\"gini = 0.5\\nsamples = 2\\nvalue = [1, 1]\\nclass = Age\", fillcolor=\"#e5813900\"] ;\n",
      "2 -> 3 ;\n",
      "4 [label=\"gini = 0.091\\nsamples = 168\\nvalue = [8, 160]\\nclass = SibSp\", fillcolor=\"#399de5f2\"] ;\n",
      "2 -> 4 ;\n",
      "5 [label=\"Fare <= -0.178\\ngini = 0.5\\nsamples = 144\\nvalue = [72, 72]\\nclass = Age\", fillcolor=\"#e5813900\"] ;\n",
      "1 -> 5 ;\n",
      "6 [label=\"gini = 0.484\\nsamples = 117\\nvalue = [48, 69]\\nclass = SibSp\", fillcolor=\"#399de54e\"] ;\n",
      "5 -> 6 ;\n",
      "7 [label=\"gini = 0.198\\nsamples = 27\\nvalue = [24, 3]\\nclass = Age\", fillcolor=\"#e58139df\"] ;\n",
      "5 -> 7 ;\n",
      "8 [label=\"Age <= -1.785\\ngini = 0.306\\nsamples = 577\\nvalue = [468, 109]\\nclass = Age\", fillcolor=\"#e58139c4\"] ;\n",
      "0 -> 8 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "9 [label=\"SibSp <= 1.794\\ngini = 0.444\\nsamples = 24\\nvalue = [8, 16]\\nclass = SibSp\", fillcolor=\"#399de57f\"] ;\n",
      "8 -> 9 ;\n",
      "10 [label=\"gini = 0.0\\nsamples = 15\\nvalue = [0, 15]\\nclass = SibSp\", fillcolor=\"#399de5ff\"] ;\n",
      "9 -> 10 ;\n",
      "11 [label=\"gini = 0.198\\nsamples = 9\\nvalue = [8, 1]\\nclass = Age\", fillcolor=\"#e58139df\"] ;\n",
      "9 -> 11 ;\n",
      "12 [label=\"Pclass_1 <= 0.601\\ngini = 0.28\\nsamples = 553\\nvalue = [460, 93]\\nclass = Age\", fillcolor=\"#e58139cb\"] ;\n",
      "8 -> 12 ;\n",
      "13 [label=\"gini = 0.204\\nsamples = 433\\nvalue = [383, 50]\\nclass = Age\", fillcolor=\"#e58139de\"] ;\n",
      "12 -> 13 ;\n",
      "14 [label=\"gini = 0.46\\nsamples = 120\\nvalue = [77, 43]\\nclass = Age\", fillcolor=\"#e5813971\"] ;\n",
      "12 -> 14 ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "txt = get_tree_dot_view(clf, list(X_train_imputed.columns), X_train_imputed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-1.2.3.tar.gz\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydot)\n",
      "Building wheels for collected packages: pydot\n",
      "  Running setup.py bdist_wheel for pydot: started\n",
      "  Running setup.py bdist_wheel for pydot: finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\DenAS\\AppData\\Local\\pip\\Cache\\wheels\\47\\8c\\c2\\4ac7bd0219b4ce5e08d03dc3467014c7a94b2efecfc29df2b2\n",
      "Successfully built pydot\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.2.3\n"
     ]
    }
   ],
   "source": [
    "#! pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pydot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DecisionTreeClassifier' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-c5afcb7a65f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_edges\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pydot.py\u001b[0m in \u001b[0;36mgraph_from_edges\u001b[1;34m(edge_list, node_prefix, directed)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'graph'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0medge\u001b[0m \u001b[1;32min\u001b[0m \u001b[0medge_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'DecisionTreeClassifier' object is not iterable"
     ]
    }
   ],
   "source": [
    "pydot.graph_from_edges(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pydot.graph_from_dot_data(open('twopi2.gv.txt').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#№from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#№scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#№scaler.fit(X_train_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_imputed_scaled = scaler.transform(X_train_imputed)\n",
    "#X_train_imputed_scaled = pd.DataFrame(X_train_imputed_scaled, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_imputed_scaled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_test_imputed_scaled = scaler.transform(imputer.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_test_imputed_scaled.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ppl = pca.fit_transform(X_train_imputed_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pca.explained_variance_ratio_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.plot(ppl[:,0], ppl[:,1],ppl[:,2],ppl[:,3], ppl[:,4], ppl[:,5], 'ro', alpha=0.1)\n",
    "#plt.title('Пассажиры Титаника')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n_clusters = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kmeans = KMeans(n_clusters=n_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#kmeans.fit(X_train_imputed_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#cluster_labels = kmeans.predict(X_train_imputed_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plt.title('Пассажиры Титаника')\n",
    "#for i,color in zip(range(n_clusters),{'aqua', 'blue', 'fuchsia', 'green', 'maroon', 'orange',\n",
    "#                  'pink', 'purple', 'red','yellow', 'violet', 'indigo', 'chartreuse', 'lime'}):\n",
    "#    t = ppl[cluster_labels==i]\n",
    "#    plt.plot(t[:,0], t[:,1], 'ro', alpha=0.1, c=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_imputed_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X_train_fin, X_val, y_train_fin, y_val = train_test_split(X_train_imputed_scaled, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
