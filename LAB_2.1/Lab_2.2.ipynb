{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание по обработке текстов\n",
    "Предсказание цены акции по экономическим новостям\n",
    "\n",
    "Входные данные:\n",
    "\n",
    "    1.Новости о компании \"Газпром\", начиная с 2010 года\n",
    "- преообразуем колонку дата в формат даты.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymystem3\n",
    "#!pip install rutermextract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>Компания рассчитывает на решение по газовому с...</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-08</th>\n",
       "      <td>Как и предполагал “Ъ”, «Газпром», воспользова...</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>Новая редакция американских санкций ставит по...</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>Как стало известно “Ъ”, известный на рынке ри...</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>НОВАТЭК, который через пять лет собирается за...</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text   len\n",
       "date                                                               \n",
       "2017-11-09  Компания рассчитывает на решение по газовому с...   419\n",
       "2017-11-08   Как и предполагал “Ъ”, «Газпром», воспользова...   624\n",
       "2017-11-01   Новая редакция американских санкций ставит по...   835\n",
       "2017-10-30   Как стало известно “Ъ”, известный на рынке ри...   436\n",
       "2017-10-23   НОВАТЭК, который через пять лет собирается за...  1272"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('texts.csv')\n",
    "df.date =  pd.to_datetime(df.date, format='%d.%m.%Y')\n",
    "df['len'] = df.text.apply(len)\n",
    "df.set_index('date', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2.Стоимость акций компании \"Газпром\" на ММВБ, начиная с 2010 года\n",
    "        цена открытия (Open)\n",
    "        цена закрытия (ClosingPrice)\n",
    "        максимальная цена за день (DailyHigh)\n",
    "        минимальная цена за день (DailyLow)\n",
    "        объем бумаг (VolumePcs)\n",
    "        \n",
    "- добавим колонку \"Дельта\" - разница между открытием и закрытием, преобразуем колонки в нужные форматы \"Дата\" или \"Число\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>delta</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-08</th>\n",
       "      <td>133.429993</td>\n",
       "      <td>132.600006</td>\n",
       "      <td>133.899994</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>16037970</td>\n",
       "      <td>0.829987</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>133.699997</td>\n",
       "      <td>133.020004</td>\n",
       "      <td>133.869995</td>\n",
       "      <td>132.809998</td>\n",
       "      <td>18198430</td>\n",
       "      <td>0.679993</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>133.330002</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.289993</td>\n",
       "      <td>132.910004</td>\n",
       "      <td>14641730</td>\n",
       "      <td>-0.669998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-05</th>\n",
       "      <td>133.479996</td>\n",
       "      <td>133.649994</td>\n",
       "      <td>133.990005</td>\n",
       "      <td>132.779999</td>\n",
       "      <td>12684800</td>\n",
       "      <td>-0.169998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04</th>\n",
       "      <td>133.009995</td>\n",
       "      <td>133.770004</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>131.929993</td>\n",
       "      <td>17818980</td>\n",
       "      <td>-0.760010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open  ClosingPrice   DailyHigh    DailyLow  VolumePcs  \\\n",
       "date                                                                      \n",
       "2017-12-08  133.429993    132.600006  133.899994  132.000000   16037970   \n",
       "2017-12-07  133.699997    133.020004  133.869995  132.809998   18198430   \n",
       "2017-12-06  133.330002    134.000000  134.289993  132.910004   14641730   \n",
       "2017-12-05  133.479996    133.649994  133.990005  132.779999   12684800   \n",
       "2017-12-04  133.009995    133.770004  134.000000  131.929993   17818980   \n",
       "\n",
       "               delta  ClosingPrice_bin  \n",
       "date                                    \n",
       "2017-12-08  0.829987                 1  \n",
       "2017-12-07  0.679993                 1  \n",
       "2017-12-06 -0.669998                 0  \n",
       "2017-12-05 -0.169998                 0  \n",
       "2017-12-04 -0.760010                 0  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_all = pd.read_csv('gazprom_prices.csv', sep=';')\n",
    "pr_all['date'] =  pd.to_datetime(pr_all.Date, format='%d.%m.%Y')\n",
    "pr_all.drop(['Date'], axis=1, inplace=True)\n",
    "pr_all['Open'] = pr_all['Open'].map(\n",
    "            lambda pr_all: np.float32(pr_all.replace(',', '.')),na_action='ignore')\n",
    "pr_all['ClosingPrice'] = pr_all['ClosingPrice'].map(\n",
    "            lambda pr_all: np.float32(pr_all.replace(',', '.')),na_action='ignore')\n",
    "pr_all['DailyHigh'] = pr_all['DailyHigh'].map(\n",
    "            lambda pr_all: np.float32(pr_all.replace(',', '.')),na_action='ignore')\n",
    "pr_all['DailyLow'] = pr_all['DailyLow'].map(\n",
    "            lambda pr_all: np.float32(pr_all.replace(',', '.')),na_action='ignore')\n",
    "pr_all['delta'] = pr_all.Open - pr_all.ClosingPrice\n",
    "pr_all['ClosingPrice_bin'] = pr_all.apply(lambda row: 1 if row.delta >= 0 else 0, axis=1)\n",
    "pr_all.set_index('date', inplace=True)\n",
    "pr_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Часть 1. Вводная\n",
    "\n",
    "Проведите предобработку текстов: если считаете нужным, выполните токенизацию, приведение к нижнему регистру, лемматизацию и/или стемминг. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Собираем общую таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>delta</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>132.309998</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>132.820007</td>\n",
       "      <td>131.139999</td>\n",
       "      <td>33869650</td>\n",
       "      <td>0.809998</td>\n",
       "      <td>1</td>\n",
       "      <td>Компания рассчитывает на решение по газовому с...</td>\n",
       "      <td>419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-08</th>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.300003</td>\n",
       "      <td>133.940002</td>\n",
       "      <td>131.580002</td>\n",
       "      <td>39381960</td>\n",
       "      <td>-0.300003</td>\n",
       "      <td>0</td>\n",
       "      <td>Как и предполагал “Ъ”, «Газпром», воспользова...</td>\n",
       "      <td>624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>126.400002</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>126.889999</td>\n",
       "      <td>125.970001</td>\n",
       "      <td>18232550</td>\n",
       "      <td>-0.099998</td>\n",
       "      <td>0</td>\n",
       "      <td>Новая редакция американских санкций ставит по...</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>125.959999</td>\n",
       "      <td>125.980003</td>\n",
       "      <td>126.930000</td>\n",
       "      <td>125.529999</td>\n",
       "      <td>19263340</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>0</td>\n",
       "      <td>Как стало известно “Ъ”, известный на рынке ри...</td>\n",
       "      <td>436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>127.050003</td>\n",
       "      <td>126.800003</td>\n",
       "      <td>127.470001</td>\n",
       "      <td>126.370003</td>\n",
       "      <td>17308800</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>НОВАТЭК, который через пять лет собирается за...</td>\n",
       "      <td>1272.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open  ClosingPrice   DailyHigh    DailyLow  VolumePcs  \\\n",
       "date                                                                      \n",
       "2017-11-09  132.309998    131.500000  132.820007  131.139999   33869650   \n",
       "2017-11-08  132.000000    132.300003  133.940002  131.580002   39381960   \n",
       "2017-11-01  126.400002    126.500000  126.889999  125.970001   18232550   \n",
       "2017-10-30  125.959999    125.980003  126.930000  125.529999   19263340   \n",
       "2017-10-23  127.050003    126.800003  127.470001  126.370003   17308800   \n",
       "\n",
       "               delta  ClosingPrice_bin  \\\n",
       "date                                     \n",
       "2017-11-09  0.809998                 1   \n",
       "2017-11-08 -0.300003                 0   \n",
       "2017-11-01 -0.099998                 0   \n",
       "2017-10-30 -0.020004                 0   \n",
       "2017-10-23  0.250000                 1   \n",
       "\n",
       "                                                         text     len  \n",
       "date                                                                   \n",
       "2017-11-09  Компания рассчитывает на решение по газовому с...   419.0  \n",
       "2017-11-08   Как и предполагал “Ъ”, «Газпром», воспользова...   624.0  \n",
       "2017-11-01   Новая редакция американских санкций ставит по...   835.0  \n",
       "2017-10-30   Как стало известно “Ъ”, известный на рынке ри...   436.0  \n",
       "2017-10-23   НОВАТЭК, который через пять лет собирается за...  1272.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = pr_all.join(df)\n",
    "Data.dropna(axis=0, inplace=True)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>delta</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1.145000e+03</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>150.018681</td>\n",
       "      <td>149.902970</td>\n",
       "      <td>151.635738</td>\n",
       "      <td>148.193511</td>\n",
       "      <td>4.492943e+07</td>\n",
       "      <td>0.115712</td>\n",
       "      <td>0.526638</td>\n",
       "      <td>772.908297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.464697</td>\n",
       "      <td>23.390248</td>\n",
       "      <td>23.702841</td>\n",
       "      <td>23.090757</td>\n",
       "      <td>2.455151e+07</td>\n",
       "      <td>2.316764</td>\n",
       "      <td>0.499508</td>\n",
       "      <td>546.978587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>107.230003</td>\n",
       "      <td>107.169998</td>\n",
       "      <td>109.199997</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>7.642310e+06</td>\n",
       "      <td>-12.639999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>135.889999</td>\n",
       "      <td>135.770004</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>2.859430e+07</td>\n",
       "      <td>-1.120003</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>144.270004</td>\n",
       "      <td>144.300003</td>\n",
       "      <td>145.889999</td>\n",
       "      <td>142.669998</td>\n",
       "      <td>3.843521e+07</td>\n",
       "      <td>0.110001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>157.169998</td>\n",
       "      <td>156.690002</td>\n",
       "      <td>158.630005</td>\n",
       "      <td>155.149994</td>\n",
       "      <td>5.580905e+07</td>\n",
       "      <td>1.310013</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.520004</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>247.470001</td>\n",
       "      <td>241.770004</td>\n",
       "      <td>2.024663e+08</td>\n",
       "      <td>13.849998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4120.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open  ClosingPrice    DailyHigh     DailyLow     VolumePcs  \\\n",
       "count  1145.000000   1145.000000  1145.000000  1145.000000  1.145000e+03   \n",
       "mean    150.018681    149.902970   151.635738   148.193511  4.492943e+07   \n",
       "std      23.464697     23.390248    23.702841    23.090757  2.455151e+07   \n",
       "min     107.230003    107.169998   109.199997   106.500000  7.642310e+06   \n",
       "25%     135.889999    135.770004   137.000000   134.500000  2.859430e+07   \n",
       "50%     144.270004    144.300003   145.889999   142.669998  3.843521e+07   \n",
       "75%     157.169998    156.690002   158.630005   155.149994  5.580905e+07   \n",
       "max     243.520004    244.000000   247.470001   241.770004  2.024663e+08   \n",
       "\n",
       "             delta  ClosingPrice_bin          len  \n",
       "count  1145.000000       1145.000000  1145.000000  \n",
       "mean      0.115712          0.526638   772.908297  \n",
       "std       2.316764          0.499508   546.978587  \n",
       "min     -12.639999          0.000000    85.000000  \n",
       "25%      -1.120003          0.000000   406.000000  \n",
       "50%       0.110001          1.000000   584.000000  \n",
       "75%       1.310013          1.000000  1010.000000  \n",
       "max      13.849998          1.000000  4120.000000  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.77 s, sys: 6.66 s, total: 8.43 s\n",
      "Wall time: 18min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from pymystem3 import Mystem\n",
    "\n",
    "def lemma(text):\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    try:\n",
    "        return \"\".join(Mystem().lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "Data['lem_text'] = Data.text.apply(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>delta</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "      <th>lem_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>132.309998</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>132.820007</td>\n",
       "      <td>131.139999</td>\n",
       "      <td>33869650</td>\n",
       "      <td>0.809998</td>\n",
       "      <td>1</td>\n",
       "      <td>Компания рассчитывает на решение по газовому с...</td>\n",
       "      <td>419.0</td>\n",
       "      <td>компания рассчитывать на решение по газовый сп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-08</th>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.300003</td>\n",
       "      <td>133.940002</td>\n",
       "      <td>131.580002</td>\n",
       "      <td>39381960</td>\n",
       "      <td>-0.300003</td>\n",
       "      <td>0</td>\n",
       "      <td>Как и предполагал “Ъ”, «Газпром», воспользова...</td>\n",
       "      <td>624.0</td>\n",
       "      <td>как и предполагать “Ъ”, «газпром», воспользова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>126.400002</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>126.889999</td>\n",
       "      <td>125.970001</td>\n",
       "      <td>18232550</td>\n",
       "      <td>-0.099998</td>\n",
       "      <td>0</td>\n",
       "      <td>Новая редакция американских санкций ставит по...</td>\n",
       "      <td>835.0</td>\n",
       "      <td>новый редакция американский санкция ставить по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>125.959999</td>\n",
       "      <td>125.980003</td>\n",
       "      <td>126.930000</td>\n",
       "      <td>125.529999</td>\n",
       "      <td>19263340</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>0</td>\n",
       "      <td>Как стало известно “Ъ”, известный на рынке ри...</td>\n",
       "      <td>436.0</td>\n",
       "      <td>как становиться известно “Ъ”, известный на рын...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>127.050003</td>\n",
       "      <td>126.800003</td>\n",
       "      <td>127.470001</td>\n",
       "      <td>126.370003</td>\n",
       "      <td>17308800</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>НОВАТЭК, который через пять лет собирается за...</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>новатэк, который через пять год собираться зап...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open  ClosingPrice   DailyHigh    DailyLow  VolumePcs  \\\n",
       "date                                                                      \n",
       "2017-11-09  132.309998    131.500000  132.820007  131.139999   33869650   \n",
       "2017-11-08  132.000000    132.300003  133.940002  131.580002   39381960   \n",
       "2017-11-01  126.400002    126.500000  126.889999  125.970001   18232550   \n",
       "2017-10-30  125.959999    125.980003  126.930000  125.529999   19263340   \n",
       "2017-10-23  127.050003    126.800003  127.470001  126.370003   17308800   \n",
       "\n",
       "               delta  ClosingPrice_bin  \\\n",
       "date                                     \n",
       "2017-11-09  0.809998                 1   \n",
       "2017-11-08 -0.300003                 0   \n",
       "2017-11-01 -0.099998                 0   \n",
       "2017-10-30 -0.020004                 0   \n",
       "2017-10-23  0.250000                 1   \n",
       "\n",
       "                                                         text     len  \\\n",
       "date                                                                    \n",
       "2017-11-09  Компания рассчитывает на решение по газовому с...   419.0   \n",
       "2017-11-08   Как и предполагал “Ъ”, «Газпром», воспользова...   624.0   \n",
       "2017-11-01   Новая редакция американских санкций ставит по...   835.0   \n",
       "2017-10-30   Как стало известно “Ъ”, известный на рынке ри...   436.0   \n",
       "2017-10-23   НОВАТЭК, который через пять лет собирается за...  1272.0   \n",
       "\n",
       "                                                     lem_text  \n",
       "date                                                           \n",
       "2017-11-09  компания рассчитывать на решение по газовый сп...  \n",
       "2017-11-08  как и предполагать “Ъ”, «газпром», воспользова...  \n",
       "2017-11-01  новый редакция американский санкция ставить по...  \n",
       "2017-10-30  как становиться известно “Ъ”, известный на рын...  \n",
       "2017-10-23  новатэк, который через пять год собираться зап...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "D['miller_count'] = D.lem_text.map(\n",
    "    lambda text: text.count('миллер') if text else 0,\n",
    "    na_action='ignore'\n",
    ")\n",
    "D['sever_count'] = D.lem_text.map(\n",
    "    lambda text: text.count('северный поток') if text else 0,\n",
    "    na_action='ignore'\n",
    ")\n",
    "D['turk_count'] = D.lem_text.map(\n",
    "    lambda text: text.count('турецкий поток') if text else 0,\n",
    "    na_action='ignore'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "Turk = D[D.turk_count > 0 ].copy()\n",
    "Turk_count = len(Turk)\n",
    "Sever = D[D.sever_count > 0 ].copy()\n",
    "Sever_count = len(Sever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ответьте на следующие вопросы:\n",
    "\n",
    "    1.Есть ли корреляция между средней длинной текста за день и ценой закрытия?\n",
    "    2.Есть ли корреляция между количеством упоминаний Алексея Миллера и ценой закрытия? Учтите разные варианты написания имени.\n",
    "    3.Упоминаний какого газопровода в статьях больше:\n",
    "        \"северный поток\"\n",
    "        \"турецкий поток\"?    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Количество статей, упоминающих Турецкий поток - 34'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Количество статей, упоминающих Северный поток - 12'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>delta</th>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "      <th>len</th>\n",
       "      <th>miller_count</th>\n",
       "      <th>sever_count</th>\n",
       "      <th>turk_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995115</td>\n",
       "      <td>0.998069</td>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.371362</td>\n",
       "      <td>0.081451</td>\n",
       "      <td>0.047017</td>\n",
       "      <td>0.014575</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.037291</td>\n",
       "      <td>-0.062884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClosingPrice</th>\n",
       "      <td>0.995115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997728</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.376791</td>\n",
       "      <td>-0.017338</td>\n",
       "      <td>-0.024772</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.035715</td>\n",
       "      <td>-0.061107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DailyHigh</th>\n",
       "      <td>0.998069</td>\n",
       "      <td>0.997728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996902</td>\n",
       "      <td>0.396443</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.015082</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.036612</td>\n",
       "      <td>-0.061706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DailyLow</th>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.996902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346697</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>0.011242</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>0.037763</td>\n",
       "      <td>-0.059570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VolumePcs</th>\n",
       "      <td>0.371362</td>\n",
       "      <td>0.376791</td>\n",
       "      <td>0.396443</td>\n",
       "      <td>0.346697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042877</td>\n",
       "      <td>-0.058108</td>\n",
       "      <td>0.076835</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.100423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>0.081451</td>\n",
       "      <td>-0.017338</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>-0.042877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726306</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>-0.012564</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>-0.019967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClosingPrice_bin</th>\n",
       "      <td>0.047017</td>\n",
       "      <td>-0.024772</td>\n",
       "      <td>0.012675</td>\n",
       "      <td>0.011242</td>\n",
       "      <td>-0.058108</td>\n",
       "      <td>0.726306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012253</td>\n",
       "      <td>-0.024272</td>\n",
       "      <td>0.026035</td>\n",
       "      <td>-0.030337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len</th>\n",
       "      <td>0.014575</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>0.015082</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.076835</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>-0.012253</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.081808</td>\n",
       "      <td>0.058477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miller_count</th>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>-0.012564</td>\n",
       "      <td>-0.024272</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164734</td>\n",
       "      <td>-0.016549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sever_count</th>\n",
       "      <td>0.037291</td>\n",
       "      <td>0.035715</td>\n",
       "      <td>0.036612</td>\n",
       "      <td>0.037763</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>0.026035</td>\n",
       "      <td>0.081808</td>\n",
       "      <td>0.164734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turk_count</th>\n",
       "      <td>-0.062884</td>\n",
       "      <td>-0.061107</td>\n",
       "      <td>-0.061706</td>\n",
       "      <td>-0.059570</td>\n",
       "      <td>-0.100423</td>\n",
       "      <td>-0.019967</td>\n",
       "      <td>-0.030337</td>\n",
       "      <td>0.058477</td>\n",
       "      <td>-0.016549</td>\n",
       "      <td>0.075493</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Open  ClosingPrice  DailyHigh  DailyLow  VolumePcs  \\\n",
       "Open              1.000000      0.995115   0.998069  0.997341   0.371362   \n",
       "ClosingPrice      0.995115      1.000000   0.997728  0.997670   0.376791   \n",
       "DailyHigh         0.998069      0.997728   1.000000  0.996902   0.396443   \n",
       "DailyLow          0.997341      0.997670   0.996902  1.000000   0.346697   \n",
       "VolumePcs         0.371362      0.376791   0.396443  0.346697   1.000000   \n",
       "delta             0.081451     -0.017338   0.035520  0.028728  -0.042877   \n",
       "ClosingPrice_bin  0.047017     -0.024772   0.012675  0.011242  -0.058108   \n",
       "len               0.014575      0.012376   0.015082  0.010711   0.076835   \n",
       "miller_count      0.006844      0.008110   0.007792  0.008442   0.007320   \n",
       "sever_count       0.037291      0.035715   0.036612  0.037763  -0.011082   \n",
       "turk_count       -0.062884     -0.061107  -0.061706 -0.059570  -0.100423   \n",
       "\n",
       "                     delta  ClosingPrice_bin       len  miller_count  \\\n",
       "Open              0.081451          0.047017  0.014575      0.006844   \n",
       "ClosingPrice     -0.017338         -0.024772  0.012376      0.008110   \n",
       "DailyHigh         0.035520          0.012675  0.015082      0.007792   \n",
       "DailyLow          0.028728          0.011242  0.010711      0.008442   \n",
       "VolumePcs        -0.042877         -0.058108  0.076835      0.007320   \n",
       "delta             1.000000          0.726306  0.022667     -0.012564   \n",
       "ClosingPrice_bin  0.726306          1.000000 -0.012253     -0.024272   \n",
       "len               0.022667         -0.012253  1.000000      0.148300   \n",
       "miller_count     -0.012564         -0.024272  0.148300      1.000000   \n",
       "sever_count       0.017115          0.026035  0.081808      0.164734   \n",
       "turk_count       -0.019967         -0.030337  0.058477     -0.016549   \n",
       "\n",
       "                  sever_count  turk_count  \n",
       "Open                 0.037291   -0.062884  \n",
       "ClosingPrice         0.035715   -0.061107  \n",
       "DailyHigh            0.036612   -0.061706  \n",
       "DailyLow             0.037763   -0.059570  \n",
       "VolumePcs           -0.011082   -0.100423  \n",
       "delta                0.017115   -0.019967  \n",
       "ClosingPrice_bin     0.026035   -0.030337  \n",
       "len                  0.081808    0.058477  \n",
       "miller_count         0.164734   -0.016549  \n",
       "sever_count          1.000000    0.075493  \n",
       "turk_count           0.075493    1.000000  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(\"Количество статей, упоминающих Турецкий поток - \" + str(Turk_count))\n",
    "display(\"Количество статей, упоминающих Северный поток - \" + str(Sever_count))\n",
    "CorrKoef = D.corr()\n",
    "CorrKoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Судя по коэффициенту корреляции длинна текста не коррелирует ни с ценой закрытия, ни, даже с дельтой за день.\n",
    "2. Судя по коэффициенту корреляции количество упоминаний Алексея Миллера не коррелирует с ценой закрытия и дельтой за день.\n",
    "3. Количество статей, упоминающих турецкий поток почти в три раза больше, чем, статей, упоминающих Северный поток."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "    4.О каких санкциях пишут в статьях?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-25 20:58:14.406273: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-02-25 20:58:14.406311: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-02-25 20:58:14.406325: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-02-25 20:58:14.426369: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2018-02-25 20:58:14.426715: I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.morphology-set input(1).token.morphology-set input(2).token.morphology-set input(3).token.morphology-set stack.token.morphology-set stack.child(1).token.morphology-set stack.child(1).sibling(-1).token.morphology-set stack.child(-1).token.morphology-set stack.child(-1).sibling(1).token.morphology-set stack.child(2).token.morphology-set stack.child(-2).token.morphology-set stack(1).token.morphology-set stack(1).child(1).token.morphology-set stack(1).child(1).sibling(-1).token.morphology-set stack(1).child(-1).token.morphology-set stack(1).child(-1).sibling(1).token.morphology-set stack(1).child(2).token.morphology-set stack(1).child(-2).token.morphology-set stack(2).token.morphology-set stack(3).token.morphology-set; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "2018-02-25 20:58:14.426741: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;morphology;tags;words\n",
      "2018-02-25 20:58:14.426755: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;32;64\n",
      "2018-02-25 20:58:14.428893: I syntaxnet/term_frequency_map.cc:101] Loaded 66 terms from ./syntaxnet/models/Russian-SynTagRus/morphology-map.\n",
      "2018-02-25 20:58:14.429854: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "2018-02-25 20:58:14.450040: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-02-25 20:58:14.450091: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-02-25 20:58:14.450112: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-02-25 20:58:14.451917: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-02-25 20:58:14.452278: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-02-25 20:58:14.452592: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2018-02-25 20:58:14.476093: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2018-02-25 20:58:14.476514: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-morph-tag input(-2).pred-morph-tag input(-3).pred-morph-tag input(-4).pred-morph-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "2018-02-25 20:58:14.476554: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "2018-02-25 20:58:14.476581: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n",
      "2018-02-25 20:58:14.482059: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2018-02-25 20:58:14.482759: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-tag input(-2).pred-tag input(-3).pred-tag input(-4).pred-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "2018-02-25 20:58:14.483008: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "2018-02-25 20:58:14.483249: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-25 20:58:15.078931: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2018-02-25 20:58:15.079016: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2018-02-25 20:58:15.091811: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "2018-02-25 20:58:16.618006: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [12 20 20 20] domain_sizes: [    37     66     33 103475]\n",
      "INFO:tensorflow:Restoring parameters from ./syntaxnet/models/Russian-SynTagRus/parser-params\n",
      "2018-02-25 20:58:18.185202: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2018-02-25 20:58:18.185259: I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.morphology-set input(1).token.morphology-set input(2).token.morphology-set input(3).token.morphology-set stack.token.morphology-set stack.child(1).token.morphology-set stack.child(1).sibling(-1).token.morphology-set stack.child(-1).token.morphology-set stack.child(-1).sibling(1).token.morphology-set stack.child(2).token.morphology-set stack.child(-2).token.morphology-set stack(1).token.morphology-set stack(1).child(1).token.morphology-set stack(1).child(1).sibling(-1).token.morphology-set stack(1).child(-1).token.morphology-set stack(1).child(-1).sibling(1).token.morphology-set stack(1).child(2).token.morphology-set stack(1).child(-2).token.morphology-set stack(2).token.morphology-set stack(3).token.morphology-set; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "2018-02-25 20:58:18.185285: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;morphology;tags;words\n",
      "2018-02-25 20:58:18.185302: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;32;64\n",
      "2018-02-25 20:58:18.187361: I syntaxnet/term_frequency_map.cc:101] Loaded 66 terms from ./syntaxnet/models/Russian-SynTagRus/morphology-map.\n",
      "2018-02-25 20:58:18.188291: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "2018-02-25 20:58:18.520250: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "2018-02-25 20:58:18.532713: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [8 8 4 8 8 8 8 4 8] domain_sizes: [     7  18750      5   8502   8502   7249   7249    449 103475]\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [8 8 4 8 8 8 8 4 8] domain_sizes: [     7  18750      5   8502   8502   7249   7249     34 103475]\n",
      "2018-02-25 20:58:20.433804: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Restoring parameters from ./syntaxnet/models/Russian-SynTagRus/tagger-params\n",
      "INFO:tensorflow:Restoring parameters from ./syntaxnet/models/Russian-SynTagRus/morpher-params\n",
      "2018-02-25 20:58:21.103256: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "2018-02-25 20:58:21.104219: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2018-02-25 20:58:21.104263: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-tag input(-2).pred-tag input(-3).pred-tag input(-4).pred-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "2018-02-25 20:58:21.104308: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "2018-02-25 20:58:21.104342: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n",
      "2018-02-25 20:58:21.123840: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2018-02-25 20:58:21.123891: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-morph-tag input(-2).pred-morph-tag input(-3).pred-morph-tag input(-4).pred-morph-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "2018-02-25 20:58:21.123918: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "2018-02-25 20:58:21.123945: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-25 20:58:21.476814: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2018-02-25 20:58:21.489717: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2018-02-25 20:58:23.597867: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "2018-02-25 20:58:23.666168: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Processed 1024 documents\n",
      "INFO:tensorflow:Processed 1024 documents\n",
      "INFO:tensorflow:Processed 1024 documents\n",
      "INFO:tensorflow:Processed 346 documents\n",
      "INFO:tensorflow:Processed 1024 documents\n",
      "INFO:tensorflow:Processed 1024 documents\n",
      "INFO:tensorflow:Total processed documents: 2394\n",
      "INFO:tensorflow:num correct tokens: 0\n",
      "INFO:tensorflow:total tokens: 123340\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 246.71, eval metric: 0.00%\n",
      "INFO:tensorflow:Processed 346 documents\n",
      "INFO:tensorflow:Processed 1024 documents\n",
      "INFO:tensorflow:Total processed documents: 2394\n",
      "INFO:tensorflow:num correct tokens: 0\n",
      "INFO:tensorflow:total tokens: 123340\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 393.12, eval metric: 0.00%\n",
      "INFO:tensorflow:Processed 346 documents\n",
      "INFO:tensorflow:Total processed documents: 2394\n",
      "INFO:tensorflow:num correct tokens: 2394\n",
      "INFO:tensorflow:total tokens: 123340\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 444.94, eval metric: 1.94%\n"
     ]
    }
   ],
   "source": [
    "! cat texts.csv | docker run --rm -i inemo/syntaxnet_rus > dat.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = 'texts.conll'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего 416 упоминаний о санкциях\n",
      "CPU times: user 1.69 s, sys: 39.9 ms, total: 1.73 s\n",
      "Wall time: 1.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import codecs\n",
    "import re\n",
    "processed_sentences = []\n",
    "sentence = []\n",
    "for line in codecs.open(train_file, 'r', 'utf-8'):\n",
    "    if len(line) == 1:\n",
    "        processed_sentences.append(sentence)\n",
    "        sentence = []\n",
    "    else:\n",
    "        word = line.split(\"\\t\")\n",
    "        sentence.append(word)\n",
    "deps = []\n",
    "res = []\n",
    "sanctions = []\n",
    "sanctions1 = []\n",
    "for sentence in processed_sentences:\n",
    "    s = u\"\"\n",
    "    for line in sentence:\n",
    "        s += u\"\\t\".join(line) + u'\\n'\n",
    "    deps.append(s)\n",
    "\n",
    "for sent_dep in deps:    \n",
    "    s_deps = sent_dep.split('\\n')\n",
    "    for one_step in s_deps:\n",
    "        if len(one_step) > 1:\n",
    "            spl_one_step = one_step.split('\\t')\n",
    "            if 'санкц' in spl_one_step[1] and not('санкционирован' in spl_one_step[1]):\n",
    "                Word_sanctions = spl_one_step[1]\n",
    "                reg = re.compile('[^а-яА-Я ]')\n",
    "                Word_sanctions = reg.sub('', Word_sanctions)                \n",
    "                number = int(spl_one_step[0]) \n",
    "                for two_step in s_deps:\n",
    "                    spl_two_step = two_step.split('\\t')\n",
    "                    if len(spl_two_step) > 1 :\n",
    "                        word_type = spl_two_step[3]\n",
    "                        if word_type == 'ADJ' :\n",
    "                            word = spl_two_step[1]\n",
    "                            reg = re.compile('[^а-яА-Я ]')\n",
    "                            word = reg.sub('', word)\n",
    "                            words = word #+ ' ' + Word_sanctions\n",
    "                            if not(word in sanctions1) and len(word)>4:\n",
    "                                sanctions1.append(word)\n",
    "                                sanctions.append(words)\n",
    "print('Всего ' + str(len(sanctions)) + ' упоминаний о санкциях')  \n",
    "sanctions.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Список санкций:\n",
      "1.американский\n",
      "2.аналогичный\n",
      "3.аяшский\n",
      "4.балтийский\n",
      "5.вильнюсский\n",
      "6.возможный\n",
      "7.высокий\n",
      "8.газпром\n",
      "9.геологический\n",
      "10.дальний\n",
      "11.долгинск\n",
      "12.донецкий\n",
      "13.европейский\n",
      "14.единый\n",
      "15.керченский\n",
      "16.крупный\n",
      "17.луганский\n",
      "18.международный\n",
      "19.морской\n",
      "20.московский\n",
      "21.национальный\n",
      "22.независимый\n",
      "23.новый\n",
      "24.общий\n",
      "25.один\n",
      "26.пекин\n",
      "27.первый\n",
      "28.петербургский\n",
      "29.печорский\n",
      "30.последний\n",
      "31.приразломный\n",
      "32.прокладка\n",
      "33.российский\n",
      "34.северный\n",
      "35.стокгольмский\n",
      "36.таможенный\n",
      "37.троицкий\n",
      "38.турецкий\n",
      "39.украинуть\n",
      "40.центральный\n",
      "41.челябинск\n",
      "42.черный\n",
      "43.чистый\n",
      "44.эффективный\n",
      "45.южнокиринский\n",
      "46.ярославский\n",
      "47.аграрный\n",
      "48.административный\n",
      "49.азиатский\n",
      "50.англоголландский\n",
      "51.антикризисный\n",
      "52.антимонопольный\n",
      "53.антироссийский\n",
      "54.арктический\n",
      "55.базовый\n",
      "56.беспрецедентный\n",
      "57.близкий\n",
      "58.большой\n",
      "59.бывший\n",
      "60.бюрократический\n",
      "61.верхний\n",
      "62.визовый\n",
      "63.виртуальный\n",
      "64.внебюджетный\n",
      "65.внешний\n",
      "66.внутренний\n",
      "67.волатильный\n",
      "68.восточный\n",
      "69.вредный\n",
      "70.второй\n",
      "71.высококонкурентный\n",
      "72.газовый\n",
      "73.газоконденсатный\n",
      "74.генеральный\n",
      "75.гибкий\n",
      "76.главный\n",
      "77.годовой\n",
      "78.государственный\n",
      "79.готовый\n",
      "80.давний\n",
      "81.дальнейший\n",
      "82.демонстрировать\n",
      "83.долговой\n",
      "84.долгосрочный\n",
      "85.должный\n",
      "86.должно\n",
      "87.дополнительный\n",
      "88.досрочный\n",
      "89.драматичный\n",
      "90.другой\n",
      "91.друг\n",
      "92.естественный\n",
      "93.железнодорожный\n",
      "94.западный\n",
      "95.зарубежный\n",
      "96.значительный\n",
      "97.известно\n",
      "98.известный\n",
      "99.имиджевой\n",
      "100.импортный\n",
      "101.инвестиционный\n",
      "102.иностранный\n",
      "103.каспийский\n",
      "104.квартальный\n",
      "105.китайский\n",
      "106.ключевой\n",
      "107.коммерческий\n",
      "108.контрактный\n",
      "109.контрольный\n",
      "110.корпоративный\n",
      "111.который\n",
      "112.кредитный\n",
      "113.крымский\n",
      "114.летний\n",
      "115.лизинговый\n",
      "116.хороший\n",
      "117.любой\n",
      "118.магистральный\n",
      "119.максимальный\n",
      "120.массовый\n",
      "121.межбанковский\n",
      "122.местный\n",
      "123.мировой\n",
      "124.налоговый\n",
      "125.народный\n",
      "126.настоящий\n",
      "127.небольшой\n",
      "128.невыбранный\n",
      "129.невыгодный\n",
      "130.недовольный\n",
      "131.неизвестный\n",
      "132.необходимый\n",
      "133.неопределенный\n",
      "134.неплатежеспособный\n",
      "135.неплохой\n",
      "136.непринципиальный\n",
      "137.неравный\n",
      "138.несанкционированный\n",
      "139.несогласованный\n",
      "140.нефтегазовый\n",
      "141.нефтепродукт\n",
      "142.нефтяной\n",
      "143.неясный\n",
      "144.низкий\n",
      "145.новое\n",
      "146.общедоступный\n",
      "147.обязанный\n",
      "148.одновременный\n",
      "149.окружной\n",
      "150.оперативный\n",
      "151.опорный\n",
      "152.определенный\n",
      "153.осеннезимнему\n",
      "154.основное\n",
      "155.основной\n",
      "156.открытый\n",
      "157.официальный\n",
      "158.очередной\n",
      "159.ощутимый\n",
      "160.паритетный\n",
      "161.партнерский\n",
      "162.персональный\n",
      "163.подвижный\n",
      "164.подводный\n",
      "165.подобный\n",
      "166.поквартальный\n",
      "167.политический\n",
      "168.постоянный\n",
      "169.предварительный\n",
      "170.предкризисный\n",
      "171.президентский\n",
      "172.природный\n",
      "173.продовольственный\n",
      "174.профильный\n",
      "175.процентный\n",
      "176.прочий\n",
      "177.прошлое\n",
      "178.прошлый\n",
      "179.прямой\n",
      "180.публичный\n",
      "181.радикальный\n",
      "182.развертывать\n",
      "183.различный\n",
      "184.реальный\n",
      "185.реверсный\n",
      "186.регуляторный\n",
      "187.рекордный\n",
      "188.репутационный\n",
      "189.ресурсный\n",
      "190.риск\n",
      "191.российскоитальянский\n",
      "192.рублевый\n",
      "193.рыболовный\n",
      "194.рынок\n",
      "195.сам\n",
      "196.самопровозглашенный\n",
      "197.самостоятельный\n",
      "198.сахалинский\n",
      "199.своевременно\n",
      "200.секторальный\n",
      "201.сельский\n",
      "202.сербский\n",
      "203.серьезный\n",
      "204.синдицировать\n",
      "205.скептически\n",
      "206.слабый\n",
      "207.сланцевый\n",
      "208.словацкий\n",
      "209.сложный\n",
      "210.собственный\n",
      "211.совместный\n",
      "212.соответствовать\n",
      "213.специальный\n",
      "214.способный\n",
      "215.среднесуточный\n",
      "216.стратегический\n",
      "217.судебный\n",
      "218.суммарный\n",
      "219.сухопутный\n",
      "220.существенный\n",
      "221.такой\n",
      "222.текущий\n",
      "223.телевизионный\n",
      "224.телефонный\n",
      "225.тендерный\n",
      "226.технологический\n",
      "227.топливный\n",
      "228.торговый\n",
      "229.трагично\n",
      "230.транзитный\n",
      "231.трейдинговый\n",
      "232.третий\n",
      "233.трехлетний\n",
      "234.трубный\n",
      "235.трубопроводный\n",
      "236.туркменский\n",
      "237.украинский\n",
      "238.уязвимый\n",
      "239.фактический\n",
      "240.февральский\n",
      "241.федеральный\n",
      "242.финансовый\n",
      "243.финансовоэкономический\n",
      "244.частный\n",
      "245.шельф\n",
      "246.шельфовый\n",
      "247.штрафной\n",
      "248.экономический\n",
      "249.экспортный\n",
      "250.энергетический\n",
      "251.это\n",
      "252.юридический\n",
      "253.якорный\n"
     ]
    }
   ],
   "source": [
    "print(\"Список санкций:\")\n",
    "sanctions.sort()\n",
    "ssss = []\n",
    "a = 0\n",
    "for s in sanctions:\n",
    "    #print(type(s))\n",
    "    #a += 1;\n",
    "    #print(s)\n",
    "    n = Mystem().lemmatize(s)\n",
    "    sankc = n[0]\n",
    "    if not(sankc in ssss):\n",
    "        a +=1\n",
    "        print(\"\" + str(a) + \".\" + sankc)\n",
    "        ssss.append(sankc)    \n",
    "    #ssss.append(sankc)\n",
    "    #ssss.append(Mystem().lemmatize(s.split()[0]))\n",
    "    #if a > 20:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Часть 2. Классификационная\n",
    "\n",
    "Вам предстоит решить следующую задачу: по текстам новостей за день определить, вырастет или понизится цена закрытия. Для этого:\n",
    "\n",
    "    бинаризуйте признак \"цена закрытия\": новый признак ClosingPrice_bin равен 1, если по сравнению со вчера цена не упала, и 0 – в обратном случаея;\n",
    "    составьте бучающее и тестовое множество: данные до начала 2016 года используются для обучения, данные с 2016 года и позже – для тестирования.\n",
    "\n",
    "Таким образом, в каждлый момент времени мы знаем:\n",
    "\n",
    "    ClosingPrice_bin – бинарый целевой признак\n",
    "    слова из статей, опубликованных в этот день – объясняющие признаки\n",
    "\n",
    "В этой части задания вам нужно сделать baseline алгоритм и попытаться его улучшить в следующей части.\n",
    "\n",
    "Используйте любой известный вам алгоритм классификации текстов для того, Используйте $tf-idf$ преобразование, сингулярное разложение, нормировку признакого пространства и любые другие техники обработки данных, которые вы считаете нужным. Используйте accuracy и F-measure для оценки качества классификации. Покажите, как $tf-idf$ преобразование или сингулярное разложение или любая другая использованная вами техника влияет на качество классификации. Если у выбранного вами алгоритма есть гиперпараметры (например, $\\alpha$ в преобразовании Лапласа для метода наивного Байеса), покажите, как изменение гиперпараметра влияет на качество классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = D['ClosingPrice_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "df = vectorizer.fit_transform(D['lem_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.44      0.43      0.43       170\n",
      "          1       0.54      0.55      0.54       208\n",
      "\n",
      "avg / total       0.49      0.49      0.49       378\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "LogReg = LogisticRegression()\n",
    "preds = LogReg.fit(X_train, y_train).predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
