{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/den/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('big_table.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drug_cod</th>\n",
       "      <th>drug_x</th>\n",
       "      <th>provider_code</th>\n",
       "      <th>provider_drug_cod</th>\n",
       "      <th>code</th>\n",
       "      <th>drug_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>9953</td>\n",
       "      <td>Ацетилсалициловая к-та 500мг №10 тб</td>\n",
       "      <td>0000000000000000000013561</td>\n",
       "      <td>5163</td>\n",
       "      <td>13561</td>\n",
       "      <td>Ацетилсалициловая к-та таб 0,5 г №10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>10604</td>\n",
       "      <td>Сульфокамфокаин 100мг/мл 2мл №10 амп р-р д/ин</td>\n",
       "      <td>0000000000000000000010250</td>\n",
       "      <td>5163</td>\n",
       "      <td>10250</td>\n",
       "      <td>Сульфокамфокаин амп 2 мл №10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>11805</td>\n",
       "      <td>Пирацетам 1200мг №20 тб пл/о</td>\n",
       "      <td>0000000000000000000017469</td>\n",
       "      <td>5163</td>\n",
       "      <td>17469</td>\n",
       "      <td>Пирацетам таб 1200 мг № 20 п/о</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>3941</td>\n",
       "      <td>Торвакард 20мг №30 тб пл/о</td>\n",
       "      <td>0000000000000000000017256</td>\n",
       "      <td>5163</td>\n",
       "      <td>17256</td>\n",
       "      <td>Торвакард 0,02 №30 таб. п\\о</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>6214</td>\n",
       "      <td>Фенистил гель 0.1% 50г (тубы)</td>\n",
       "      <td>0000000000000000000015263</td>\n",
       "      <td>5163</td>\n",
       "      <td>15263</td>\n",
       "      <td>Фенистил  0,1% гель 50 г</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>5111</td>\n",
       "      <td>Бетасерк 24мг №20 тб</td>\n",
       "      <td>0000000000000000000014629</td>\n",
       "      <td>5163</td>\n",
       "      <td>14629</td>\n",
       "      <td>Бетасерк таб 24 мг №20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>5132</td>\n",
       "      <td>Дибазол - УБФ 20мг №10 тб</td>\n",
       "      <td>0000000000000000000008789</td>\n",
       "      <td>5163</td>\n",
       "      <td>8789</td>\n",
       "      <td>Дибазол таб 20 мг №10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>6229</td>\n",
       "      <td>Клотримазол 100мг №6 тб ваг</td>\n",
       "      <td>0000000000000000000010395</td>\n",
       "      <td>5163</td>\n",
       "      <td>10395</td>\n",
       "      <td>Клотримазол таб ваг 100 мг №6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>4145</td>\n",
       "      <td>Мидокалм Рихтер 100мг+2,5мг/мл 1мл №5 амп р-р...</td>\n",
       "      <td>0000000000000000000014400</td>\n",
       "      <td>5163</td>\n",
       "      <td>14400</td>\n",
       "      <td>Мидокалм-Рихтер  амп 100 мг+2,5 мг/мл 1 мл №5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>6191</td>\n",
       "      <td>Гевискон форте (мята) 150мл №1 сусп фл</td>\n",
       "      <td>0000000000000000000018330</td>\n",
       "      <td>5163</td>\n",
       "      <td>18330</td>\n",
       "      <td>Гевискон форте сусп фл 150 мл мятный</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0  drug_cod                                             drug_x  \\\n",
       "25          25      9953                Ацетилсалициловая к-та 500мг №10 тб   \n",
       "26          26     10604      Сульфокамфокаин 100мг/мл 2мл №10 амп р-р д/ин   \n",
       "27          27     11805                       Пирацетам 1200мг №20 тб пл/о   \n",
       "28          28      3941                         Торвакард 20мг №30 тб пл/о   \n",
       "29          29      6214                      Фенистил гель 0.1% 50г (тубы)   \n",
       "30          30      5111                               Бетасерк 24мг №20 тб   \n",
       "31          31      5132                          Дибазол - УБФ 20мг №10 тб   \n",
       "32          32      6229                        Клотримазол 100мг №6 тб ваг   \n",
       "33          33      4145   Мидокалм Рихтер 100мг+2,5мг/мл 1мл №5 амп р-р...   \n",
       "34          34      6191             Гевискон форте (мята) 150мл №1 сусп фл   \n",
       "\n",
       "                provider_code  provider_drug_cod   code  \\\n",
       "25  0000000000000000000013561               5163  13561   \n",
       "26  0000000000000000000010250               5163  10250   \n",
       "27  0000000000000000000017469               5163  17469   \n",
       "28  0000000000000000000017256               5163  17256   \n",
       "29  0000000000000000000015263               5163  15263   \n",
       "30  0000000000000000000014629               5163  14629   \n",
       "31  0000000000000000000008789               5163   8789   \n",
       "32  0000000000000000000010395               5163  10395   \n",
       "33  0000000000000000000014400               5163  14400   \n",
       "34  0000000000000000000018330               5163  18330   \n",
       "\n",
       "                                           drug_y  \n",
       "25           Ацетилсалициловая к-та таб 0,5 г №10  \n",
       "26                   Сульфокамфокаин амп 2 мл №10  \n",
       "27                 Пирацетам таб 1200 мг № 20 п/о  \n",
       "28                    Торвакард 0,02 №30 таб. п\\о  \n",
       "29                       Фенистил  0,1% гель 50 г  \n",
       "30                         Бетасерк таб 24 мг №20  \n",
       "31                          Дибазол таб 20 мг №10  \n",
       "32                  Клотримазол таб ваг 100 мг №6  \n",
       "33  Мидокалм-Рихтер  амп 100 мг+2,5 мг/мл 1 мл №5  \n",
       "34           Гевискон форте сусп фл 150 мл мятный  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[25:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество строк в списке Парма Медикал: 20206\n",
      "Количество строк в списке сторонних организаций: 20206\n",
      "Количество уникальных препаратов Парма Медикал: 7230\n"
     ]
    }
   ],
   "source": [
    "Parma_Sentence = data.drug_x.tolist()\n",
    "Parma_drug_cod = data.drug_cod.tolist()\n",
    "Other_Sentence = data.drug_y.tolist()\n",
    "Other_Sentence = ['B' + ''.join(DrugName)  + 'E' for DrugName in Other_Sentence]\n",
    "Parma_Sentence = ['B' + ''.join(DrugName)  + 'E' for DrugName in Parma_Sentence]\n",
    "print('Количество строк в списке Парма Медикал:', len(Parma_Sentence), sep = ' ')\n",
    "print('Количество строк в списке сторонних организаций:', len(Other_Sentence), sep = ' ')\n",
    "PM_unik_drug = set()\n",
    "for drug_line in Parma_drug_cod:\n",
    "    if (drug_line not in PM_unik_drug):\n",
    "        PM_unik_drug.add(drug_line)\n",
    "PM_unik_drug = sorted(list(PM_unik_drug))    \n",
    "PM_unik_drug = set(PM_unik_drug)\n",
    "print('Количество уникальных препаратов Парма Медикал:',len(PM_unik_drug), sep = ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B Пентоксифиллин 100мг №60 тб п/о кшчр E', 'B Валериана Форте 40мг №50 тб пл/оE', 'B Луцетам 200мг/мл 5мл №10 р-р д/в/м и в/в введенияE', 'B Амитриптилин 25мг №50 тбE', 'B Брусники листья №20 1,5г ф/пE', 'B Тест-полоски  Аккучек Перформа №50 E', 'B Дексалгин 25мг №10 тб пл/о E', 'B Гастал №30 тб д/рассE', 'B Гастал №30 тб д/рассE', 'B Белогент 15г №1 крем для нар прим тубаE']\n",
      "['BПентоксифиллин таб.п/к/о 0,1 №60 ФармпроектE', 'BВалериана форте таб. п.о 40мг №50  E', 'BЛуцетам р-р в/в и в/м 200мг/мл 5мл №10  E', 'BАмитриптилин таб. 25мг №50  E', 'BБрусника листья 1,5г №20  E', 'BАкку-чек перформа тест-полоски д/глюкометра №50  E', 'BДексалгин таб. п.о 25мг №10  E', 'BГастал таб. д/рассас №30  E', 'BГастал таб. д/рассас №30  E', 'BБелогент крем 15г  E']\n"
     ]
    }
   ],
   "source": [
    "print(Parma_Sentence[1225:1235], Other_Sentence[1225:1235], sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PM_chars = set()\n",
    "for drug_line in Parma_Sentence:\n",
    "    for ch in drug_line:\n",
    "        if (ch not in PM_chars):\n",
    "            PM_chars.add(ch)\n",
    "PM_chars = sorted(list(PM_chars))    \n",
    "PM_chars = set(PM_chars)\n",
    "display(len(PM_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "151"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Other_chars = set()\n",
    "display(type(Other_chars))\n",
    "for drug_line in Other_Sentence:\n",
    "    for ch in drug_line:\n",
    "        if (ch not in Other_chars):\n",
    "            Other_chars.add(ch)\n",
    "Other_chars = sorted(list(Other_chars))\n",
    "Other_chars = set(Other_chars)\n",
    "display(len(Other_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#display(PM_chars, Other_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Сравнение словарей:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Нет в словаре ПМ:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'#', '=', '@', 'J', '\\\\', 'j', 'z', '\\xa0', 'Щ', 'Ъ', 'Ы', 'Ь', '–'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Нет во внешнем словаре:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "set"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'&', '<', '>'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Дилемма - добавлять ли во внешние словари символы ПМ? Они же могут там рано или поздно появиться.'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'А, давайте-ка добавим!'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Проверкочка:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Количество симовлов, которых нет во внешнем словаре:0'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display('Сравнение словарей:')\n",
    "display('Нет в словаре ПМ:')\n",
    "display(Other_chars - PM_chars)\n",
    "display('Нет во внешнем словаре:')\n",
    "display(type(PM_chars))\n",
    "display(type(Other_chars))\n",
    "delta = PM_chars - Other_chars\n",
    "display(delta)\n",
    "display('Дилемма - добавлять ли во внешние словари символы ПМ? Они же могут там рано или поздно появиться.')\n",
    "display('А, давайте-ка добавим!')\n",
    "for ch in delta:\n",
    "    Other_chars.add(ch)\n",
    "display('Проверкочка:')\n",
    "delta = PM_chars - Other_chars\n",
    "display(\"Количество симовлов, которых нет во внешнем словаре:\" + str(len(delta)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PM_index_to_char_dict = {}\n",
    "PM_char_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(PM_chars):\n",
    "    PM_index_to_char_dict[k] = v\n",
    "    PM_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Other_index_to_char_dict = {}\n",
    "Other_char_to_index_dict = {}\n",
    "\n",
    "for k, v in enumerate(Other_chars):\n",
    "    Other_index_to_char_dict[k] = v\n",
    "    Other_char_to_index_dict[v] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_PM_sent = max([len(line) for line in Parma_Sentence])\n",
    "max_len_Other_sent = max([len(line) for line in Other_Sentence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(max_len_PM_sent)\n",
    "display(max_len_Other_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nb_samples = 20206\n",
    "#nb_samples = 1000\n",
    "tokenized_Other_sentences = np.zeros(shape = (nb_samples,max_len_Other_sent,len(Other_chars)), dtype='float32')\n",
    "#print(tokenized_Other_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_PM_sentences = np.zeros(shape = (nb_samples,max_len_PM_sent,len(PM_chars)), dtype='float32')\n",
    "#print(tokenized_PM_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_data = np.zeros((nb_samples, max_len_PM_sent, len(PM_chars)),dtype='float32')\n",
    "#print(target_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(nb_samples):\n",
    "    for k,ch in enumerate(Other_Sentence[i]):\n",
    "        tokenized_Other_sentences[i,k,Other_char_to_index_dict[ch]] = 1\n",
    "        \n",
    "    for k,ch in enumerate(Parma_Sentence[i]):\n",
    "        tokenized_PM_sentences[i,k,PM_char_to_index_dict[ch]] = 1\n",
    "\n",
    "        # decoder_target_data will be ahead by one timestep and will not include the start character.\n",
    "        if k > 0:\n",
    "            target_data[i,k-1,PM_char_to_index_dict[ch]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(None,len(Other_chars)))\n",
    "encoder_LSTM = LSTM(256,return_state = True)\n",
    "encoder_outputs, encoder_h, encoder_c = encoder_LSTM (encoder_input)\n",
    "encoder_states = [encoder_h, encoder_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None,len(PM_chars)))\n",
    "decoder_LSTM = LSTM(256,return_sequences=True, return_state = True)\n",
    "decoder_out, _ , _ = decoder_LSTM(decoder_input, initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(PM_chars),activation='softmax')\n",
    "decoder_out = decoder_dense (decoder_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(None), Dimension(141)])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16164 samples, validate on 4042 samples\n",
      "Epoch 1/120\n",
      "16164/16164 [==============================] - 302s 19ms/step - loss: 1.0711 - val_loss: 0.9831\n",
      "Epoch 2/120\n",
      "16164/16164 [==============================] - 307s 19ms/step - loss: 0.9217 - val_loss: 0.7576\n",
      "Epoch 3/120\n",
      "16164/16164 [==============================] - 418s 26ms/step - loss: 0.7418 - val_loss: 0.6606\n",
      "Epoch 4/120\n",
      "16164/16164 [==============================] - 561s 35ms/step - loss: 0.6550 - val_loss: 0.5983\n",
      "Epoch 5/120\n",
      "16164/16164 [==============================] - 582s 36ms/step - loss: 0.6071 - val_loss: 0.5540\n",
      "Epoch 6/120\n",
      "16164/16164 [==============================] - 513s 32ms/step - loss: 0.5687 - val_loss: 0.5271\n",
      "Epoch 7/120\n",
      "16164/16164 [==============================] - 458s 28ms/step - loss: 0.5430 - val_loss: 0.5157\n",
      "Epoch 8/120\n",
      "16164/16164 [==============================] - 449s 28ms/step - loss: 0.5312 - val_loss: 0.4831\n",
      "Epoch 9/120\n",
      "16164/16164 [==============================] - 395s 24ms/step - loss: 0.5041 - val_loss: 0.4703\n",
      "Epoch 10/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.4862 - val_loss: 0.4549\n",
      "Epoch 11/120\n",
      "16164/16164 [==============================] - 395s 24ms/step - loss: 0.4699 - val_loss: 0.4410\n",
      "Epoch 12/120\n",
      "16164/16164 [==============================] - 346s 21ms/step - loss: 0.4554 - val_loss: 0.4244\n",
      "Epoch 13/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.4402 - val_loss: 0.4115\n",
      "Epoch 14/120\n",
      "16164/16164 [==============================] - 320s 20ms/step - loss: 0.4262 - val_loss: 0.3993\n",
      "Epoch 15/120\n",
      "16164/16164 [==============================] - 323s 20ms/step - loss: 0.4130 - val_loss: 0.3912\n",
      "Epoch 16/120\n",
      "16164/16164 [==============================] - 323s 20ms/step - loss: 0.4004 - val_loss: 0.3748\n",
      "Epoch 17/120\n",
      "16164/16164 [==============================] - 323s 20ms/step - loss: 0.3877 - val_loss: 0.3670\n",
      "Epoch 18/120\n",
      "16164/16164 [==============================] - 323s 20ms/step - loss: 0.3756 - val_loss: 0.3587\n",
      "Epoch 19/120\n",
      "16164/16164 [==============================] - 424s 26ms/step - loss: 0.3644 - val_loss: 0.3452\n",
      "Epoch 20/120\n",
      "16164/16164 [==============================] - 463s 29ms/step - loss: 0.3561 - val_loss: 0.3364\n",
      "Epoch 21/120\n",
      "16164/16164 [==============================] - 455s 28ms/step - loss: 0.3429 - val_loss: 0.3322\n",
      "Epoch 22/120\n",
      "16164/16164 [==============================] - 420s 26ms/step - loss: 0.3331 - val_loss: 0.3201\n",
      "Epoch 23/120\n",
      "16164/16164 [==============================] - 394s 24ms/step - loss: 0.3235 - val_loss: 0.3079\n",
      "Epoch 24/120\n",
      "16164/16164 [==============================] - 358s 22ms/step - loss: 0.3134 - val_loss: 0.3010\n",
      "Epoch 25/120\n",
      "16164/16164 [==============================] - 311s 19ms/step - loss: 0.3115 - val_loss: 0.3042\n",
      "Epoch 26/120\n",
      "16164/16164 [==============================] - 307s 19ms/step - loss: 0.3012 - val_loss: 0.2917\n",
      "Epoch 27/120\n",
      "16164/16164 [==============================] - 307s 19ms/step - loss: 0.2916 - val_loss: 0.2854\n",
      "Epoch 28/120\n",
      "16164/16164 [==============================] - 306s 19ms/step - loss: 0.2834 - val_loss: 0.2761\n",
      "Epoch 29/120\n",
      "16164/16164 [==============================] - 306s 19ms/step - loss: 0.2757 - val_loss: 0.2678\n",
      "Epoch 30/120\n",
      "16164/16164 [==============================] - 306s 19ms/step - loss: 0.2683 - val_loss: 0.2670\n",
      "Epoch 31/120\n",
      "16164/16164 [==============================] - 307s 19ms/step - loss: 0.2615 - val_loss: 0.2612\n",
      "Epoch 32/120\n",
      "16164/16164 [==============================] - 307s 19ms/step - loss: 0.2550 - val_loss: 0.2503\n",
      "Epoch 33/120\n",
      "16164/16164 [==============================] - 307s 19ms/step - loss: 0.2488 - val_loss: 0.2475\n",
      "Epoch 34/120\n",
      "16164/16164 [==============================] - 307s 19ms/step - loss: 0.2429 - val_loss: 0.2402\n",
      "Epoch 35/120\n",
      "16164/16164 [==============================] - 326s 20ms/step - loss: 0.2377 - val_loss: 0.2367\n",
      "Epoch 36/120\n",
      "16164/16164 [==============================] - 467s 29ms/step - loss: 0.2323 - val_loss: 0.2332\n",
      "Epoch 37/120\n",
      "16164/16164 [==============================] - 468s 29ms/step - loss: 0.2270 - val_loss: 0.2306\n",
      "Epoch 38/120\n",
      "16164/16164 [==============================] - 433s 27ms/step - loss: 0.2224 - val_loss: 0.2340\n",
      "Epoch 39/120\n",
      "16164/16164 [==============================] - 397s 25ms/step - loss: 0.2178 - val_loss: 0.2286\n",
      "Epoch 40/120\n",
      "16164/16164 [==============================] - 332s 21ms/step - loss: 0.2136 - val_loss: 0.2199\n",
      "Epoch 41/120\n",
      "16164/16164 [==============================] - 357s 22ms/step - loss: 0.2093 - val_loss: 0.2156\n",
      "Epoch 42/120\n",
      "16164/16164 [==============================] - 451s 28ms/step - loss: 0.2055 - val_loss: 0.2152\n",
      "Epoch 43/120\n",
      "16164/16164 [==============================] - 341s 21ms/step - loss: 0.2018 - val_loss: 0.2134\n",
      "Epoch 44/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1981 - val_loss: 0.2072\n",
      "Epoch 45/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1946 - val_loss: 0.2030\n",
      "Epoch 46/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1911 - val_loss: 0.2041\n",
      "Epoch 47/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1884 - val_loss: 0.1974\n",
      "Epoch 48/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1854 - val_loss: 0.1998\n",
      "Epoch 49/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1823 - val_loss: 0.1976\n",
      "Epoch 50/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1793 - val_loss: 0.1958\n",
      "Epoch 51/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1769 - val_loss: 0.1943\n",
      "Epoch 52/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1744 - val_loss: 0.1877\n",
      "Epoch 53/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1719 - val_loss: 0.1872\n",
      "Epoch 54/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1696 - val_loss: 0.1824\n",
      "Epoch 55/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1670 - val_loss: 0.1839\n",
      "Epoch 56/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1654 - val_loss: 0.1829\n",
      "Epoch 57/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1631 - val_loss: 0.1835\n",
      "Epoch 58/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1610 - val_loss: 0.1762\n",
      "Epoch 59/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1590 - val_loss: 0.1744\n",
      "Epoch 60/120\n",
      "16164/16164 [==============================] - 323s 20ms/step - loss: 0.1572 - val_loss: 0.1825\n",
      "Epoch 61/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1556 - val_loss: 0.1721\n",
      "Epoch 62/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1538 - val_loss: 0.1731\n",
      "Epoch 63/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1518 - val_loss: 0.1711\n",
      "Epoch 64/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1507 - val_loss: 0.1720\n",
      "Epoch 65/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1487 - val_loss: 0.1669\n",
      "Epoch 66/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1477 - val_loss: 0.1697\n",
      "Epoch 67/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1461 - val_loss: 0.1633\n",
      "Epoch 68/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1445 - val_loss: 0.1633\n",
      "Epoch 69/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1434 - val_loss: 0.1634\n",
      "Epoch 70/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1418 - val_loss: 0.1630\n",
      "Epoch 71/120\n",
      "16164/16164 [==============================] - 323s 20ms/step - loss: 0.1407 - val_loss: 0.1696\n",
      "Epoch 72/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1397 - val_loss: 0.1610\n",
      "Epoch 73/120\n",
      "16164/16164 [==============================] - 323s 20ms/step - loss: 0.1381 - val_loss: 0.1585\n",
      "Epoch 74/120\n",
      "16164/16164 [==============================] - 323s 20ms/step - loss: 0.1372 - val_loss: 0.1612\n",
      "Epoch 75/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1358 - val_loss: 0.1591\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/120\n",
      "16164/16164 [==============================] - 327s 20ms/step - loss: 0.1352 - val_loss: 0.1572\n",
      "Epoch 77/120\n",
      "16164/16164 [==============================] - 462s 29ms/step - loss: 0.1341 - val_loss: 0.1608\n",
      "Epoch 78/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1329 - val_loss: 0.1585\n",
      "Epoch 79/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1323 - val_loss: 0.1562\n",
      "Epoch 80/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1310 - val_loss: 0.1573\n",
      "Epoch 81/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1301 - val_loss: 0.1548\n",
      "Epoch 82/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1291 - val_loss: 0.1565\n",
      "Epoch 83/120\n",
      "16164/16164 [==============================] - 427s 26ms/step - loss: 0.1286 - val_loss: 0.1553\n",
      "Epoch 84/120\n",
      "16164/16164 [==============================] - 320s 20ms/step - loss: 0.1275 - val_loss: 0.1520\n",
      "Epoch 85/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1267 - val_loss: 0.1554\n",
      "Epoch 86/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1262 - val_loss: 0.1524\n",
      "Epoch 87/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1252 - val_loss: 0.1521\n",
      "Epoch 88/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1242 - val_loss: 0.1527\n",
      "Epoch 89/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1238 - val_loss: 0.1511\n",
      "Epoch 90/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1229 - val_loss: 0.1512\n",
      "Epoch 91/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1226 - val_loss: 0.1526\n",
      "Epoch 92/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1219 - val_loss: 0.1486\n",
      "Epoch 93/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1212 - val_loss: 0.1479\n",
      "Epoch 94/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1205 - val_loss: 0.1514\n",
      "Epoch 95/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1198 - val_loss: 0.1476\n",
      "Epoch 96/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1193 - val_loss: 0.1493\n",
      "Epoch 97/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1186 - val_loss: 0.1475\n",
      "Epoch 98/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1179 - val_loss: 0.1499\n",
      "Epoch 99/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1175 - val_loss: 0.1471\n",
      "Epoch 100/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1170 - val_loss: 0.1477\n",
      "Epoch 101/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1166 - val_loss: 0.1469\n",
      "Epoch 102/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1162 - val_loss: 0.1455\n",
      "Epoch 103/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1155 - val_loss: 0.1486\n",
      "Epoch 104/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1151 - val_loss: 0.1447\n",
      "Epoch 105/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1148 - val_loss: 0.1444\n",
      "Epoch 106/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1142 - val_loss: 0.1448\n",
      "Epoch 107/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1136 - val_loss: 0.1482\n",
      "Epoch 108/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1132 - val_loss: 0.1487\n",
      "Epoch 109/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1128 - val_loss: 0.1435\n",
      "Epoch 110/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1128 - val_loss: 0.1447\n",
      "Epoch 111/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1120 - val_loss: 0.1426\n",
      "Epoch 112/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1114 - val_loss: 0.1444\n",
      "Epoch 113/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1112 - val_loss: 0.1444\n",
      "Epoch 114/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1111 - val_loss: 0.1437\n",
      "Epoch 115/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1105 - val_loss: 0.1427\n",
      "Epoch 116/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1102 - val_loss: 0.1414\n",
      "Epoch 117/120\n",
      "16164/16164 [==============================] - 321s 20ms/step - loss: 0.1098 - val_loss: 0.1425\n",
      "Epoch 118/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1095 - val_loss: 0.1411\n",
      "Epoch 119/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1092 - val_loss: 0.1419\n",
      "Epoch 120/120\n",
      "16164/16164 [==============================] - 322s 20ms/step - loss: 0.1087 - val_loss: 0.1418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f23d19351d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(inputs=[encoder_input, decoder_input],outputs=[decoder_out])\n",
    "\n",
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit(x=[tokenized_Other_sentences,tokenized_PM_sentences], \n",
    "          y=target_data,\n",
    "          batch_size=164,\n",
    "          epochs=120,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model_inf = Model(encoder_input, encoder_states)\n",
    "\n",
    "# Decoder inference model\n",
    "decoder_state_input_h = Input(shape=(256,))\n",
    "decoder_state_input_c = Input(shape=(256,))\n",
    "decoder_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_out, decoder_h, decoder_c = decoder_LSTM(decoder_input, \n",
    "                                                 initial_state=decoder_input_states)\n",
    "\n",
    "decoder_states = [decoder_h , decoder_c]\n",
    "\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "\n",
    "decoder_model_inf = Model(inputs=[decoder_input] + decoder_input_states,\n",
    "                          outputs=[decoder_out] + decoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq):\n",
    "    \n",
    "    # Initial states value is coming from the encoder \n",
    "    states_val = encoder_model_inf.predict(inp_seq)\n",
    "    \n",
    "    target_seq = np.zeros((1, 1, len(PM_chars)))\n",
    "    target_seq[0, 0,PM_char_to_index_dict[' ']] = 1\n",
    "    \n",
    "    translated_sent = ''\n",
    "    stop_condition = False\n",
    "    \n",
    "    while not stop_condition:\n",
    "        \n",
    "        decoder_out, decoder_h, decoder_c = decoder_model_inf.predict(x=[target_seq] + states_val)\n",
    "        \n",
    "        max_val_index = np.argmax(decoder_out[0,-1,:])\n",
    "        sampled_PM_char = PM_index_to_char_dict[max_val_index]\n",
    "        translated_sent += sampled_PM_char\n",
    "        \n",
    "        if ( (sampled_PM_char == '\\n') or (len(translated_sent) > max_len_PM_sent)) :\n",
    "            stop_condition = True\n",
    "        \n",
    "        target_seq = np.zeros((1, 1, len(PM_chars)))\n",
    "        target_seq[0, 0, max_val_index] = 1\n",
    "        \n",
    "        states_val = [decoder_h, decoder_c]\n",
    "        \n",
    "    return translated_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: BИмудон таб д/рассас №24E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BГлаумакс 0,005% 2,5 мл фл-кап гл каплиE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BЭссенциале-форте Н капс 300 мг №30.E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BЭссенциале-форте Н капс 300 мг №30.E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BДимедрол таб №10E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BИбупрофен гель 5% 50г тубаE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BГевискон сусп фл 300 мл мятныйE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BНурофен сусп фл 100 мг/5 мл 150 мл (апельсин) для детейE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BНурофен сусп фл 100 мг/5 мл 150 мл (клубничная) для детейE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BНормодипин таб 10 мг №30E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BРанитидин таб 150 мг №20 (инд уп)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BАцетилсалициловая к-та таб 0,5 г №10E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BАримидекс таб 1 мг №28 (инд уп)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BЦерепро капс 400 мг №14E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BНитроспрей 0,4 мг/доза 200 доз 10 мл (инд уп)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BФуросемид таб 40 мг №50E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BБинт гипсовый 10х300E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BАльфа-Токоферола ацетат (витамин Е) фл 300 мг/мл 50 мл р-р в маслеE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BРибоксин таб 200 мг №50 (инд уп)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BЛейкопластырь катушка 3х300 ( инд уп).E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BБисептол таб 480 мг №28E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BПиона настойка фл 25 мл (инд уп)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BПерчатки смотровые латексные н/стер р. МАЛ (пара)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BБлоктран таб 50 мг №30E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BЭнтерофурил капс 100 мг №30E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BАцетилсалициловая к-та таб 0,5 г №10E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BСульфокамфокаин амп 2 мл №10E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BПирацетам таб 1200 мг № 20 п/оE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BТорвакард 0,02 №30 таб. п\\оE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BФенистил  0,1% гель 50 гE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(30):\n",
    "    inp_seq = tokenized_Other_sentences[seq_index:seq_index+1]\n",
    "    translated_sent = decode_seq(inp_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', Other_Sentence[seq_index])\n",
    "    print('Decoded sentence:', translated_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/den/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py:2364: UserWarning: Layer lstm_2 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 'lstm_1/while/Exit_2:0' shape=(?, 256) dtype=float32>, <tf.Tensor 'lstm_1/while/Exit_3:0' shape=(?, 256) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  str(node.arguments) + '. They will not be included '\n"
     ]
    }
   ],
   "source": [
    "# Генерируем описание модели в формате json\n",
    "model_json = model.to_json()\n",
    "# Записываем модель в файл\n",
    "json_file = open(\"my_model.json\", \"w\")\n",
    "json_file.write(model_json)\n",
    "json_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: BВанкорус (Ванкомицин) фл 1 г в/в (инд уп)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BНексиум таб 40 мг №28E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BТизалуд таб 2 мг №30E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BЦетиризин таб 10 мг №10E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BАнтигриппин шип таб №10 грейпфрутE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BАмикацин фл 1000 мг в/м в/в (для стационаров)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BПумпан капли фл 20 млE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BДона амп 200 мг/мл 2 мл №6 в/м с растворителемE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BВалерианы настойка фл 25 мл (инд уп)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BКеторол амп №10  в/в в/мE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BБронхорус 3 мг/мл 100 мл сироп (инд уп) для детейE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BМикразим капс 10000ЕД №20 (инд уп)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BТамоксифен таб 20 мг №30 (инд уп)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BНовокаин амп 0,5% 10 мл №10E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BФурадонин Авексима таб 50 мг №10E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BСалфетка спиртовая д/инъекций 30х60 ммE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BНово-Пассит р-р фл 200 млE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BКалия хлорид амп 4% 10 мл №10 р-рE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BНатрия хлорид амп 0,9% 10 мл №10.E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BРисперидон таб 2 мг №20E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BДиклофенак капли глаз 0,1% 5 млE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BВазелиновое масло фл 100 мл пластик БиолайнE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BНимулид сусп 50 мг/5 мл фл 60 млE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BАцекардол таб 50 мг №30 (инд уп)  (Ацетилсалициловая к-та)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BЦипрофлоксацин таб 500 мг №10E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BИзокет спрей 1,25 мг/доза 300 доз 15 мл п/язE\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BЦефалексин капс 0,5 г №16E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BЛефлобакт таб 250 мг №10E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BКаптоприл таб 50 мг №20 (инд уп)E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n",
      "-\n",
      "Input sentence: BВеро-Амлодипин таб 10 мг №30E\n",
      "Decoded sentence:  Коделак Бронхо №10 тбEEфиптEEкиылипекиEEапеличечичерикEEEEEЛЛТ,,,000,0,000000 1мафлин д/ростиома вледли\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(60,90):\n",
    "    inp_seq = tokenized_Other_sentences[seq_index:seq_index+1]\n",
    "    translated_sent = decode_seq(inp_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', Other_Sentence[seq_index])\n",
    "    print('Decoded sentence:', translated_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2018, 3, 21, 2, 32, 41, 388344)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
