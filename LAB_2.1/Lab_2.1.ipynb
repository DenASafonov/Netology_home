{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание по обработке текстов\n",
    "Предсказание цены акции по экономическим новостям\n",
    "\n",
    "Входные данные:\n",
    "\n",
    "    1.Новости о компании \"Газпром\", начиная с 2010 года\n",
    "- преообразуем колонку дата в формат даты.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>Компания рассчитывает на решение по газовому с...</td>\n",
       "      <td>419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-08</th>\n",
       "      <td>Как и предполагал “Ъ”, «Газпром», воспользова...</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>Новая редакция американских санкций ставит по...</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>Как стало известно “Ъ”, известный на рынке ри...</td>\n",
       "      <td>436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>НОВАТЭК, который через пять лет собирается за...</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         text   len\n",
       "date                                                               \n",
       "2017-11-09  Компания рассчитывает на решение по газовому с...   419\n",
       "2017-11-08   Как и предполагал “Ъ”, «Газпром», воспользова...   624\n",
       "2017-11-01   Новая редакция американских санкций ставит по...   835\n",
       "2017-10-30   Как стало известно “Ъ”, известный на рынке ри...   436\n",
       "2017-10-23   НОВАТЭК, который через пять лет собирается за...  1272"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('texts.csv')\n",
    "df.date =  pd.to_datetime(df.date, format='%d.%m.%Y')\n",
    "df['len'] = df.text.apply(len)\n",
    "df.set_index('date', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2.Стоимость акций компании \"Газпром\" на ММВБ, начиная с 2010 года\n",
    "        цена открытия (Open)\n",
    "        цена закрытия (ClosingPrice)\n",
    "        максимальная цена за день (DailyHigh)\n",
    "        минимальная цена за день (DailyLow)\n",
    "        объем бумаг (VolumePcs)\n",
    "        \n",
    "- добавим колонку \"Дельта\" - разница между открытием и закрытием, преобразуем колонки в нужные форматы \"Дата\" или \"Число\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-12-08</th>\n",
       "      <td>133.429993</td>\n",
       "      <td>132.600006</td>\n",
       "      <td>133.899994</td>\n",
       "      <td>132.000000</td>\n",
       "      <td>16037970</td>\n",
       "      <td>0.829987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-07</th>\n",
       "      <td>133.699997</td>\n",
       "      <td>133.020004</td>\n",
       "      <td>133.869995</td>\n",
       "      <td>132.809998</td>\n",
       "      <td>18198430</td>\n",
       "      <td>0.679993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-06</th>\n",
       "      <td>133.330002</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>134.289993</td>\n",
       "      <td>132.910004</td>\n",
       "      <td>14641730</td>\n",
       "      <td>-0.669998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-05</th>\n",
       "      <td>133.479996</td>\n",
       "      <td>133.649994</td>\n",
       "      <td>133.990005</td>\n",
       "      <td>132.779999</td>\n",
       "      <td>12684800</td>\n",
       "      <td>-0.169998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-04</th>\n",
       "      <td>133.009995</td>\n",
       "      <td>133.770004</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>131.929993</td>\n",
       "      <td>17818980</td>\n",
       "      <td>-0.760010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open  ClosingPrice   DailyHigh    DailyLow  VolumePcs  \\\n",
       "date                                                                      \n",
       "2017-12-08  133.429993    132.600006  133.899994  132.000000   16037970   \n",
       "2017-12-07  133.699997    133.020004  133.869995  132.809998   18198430   \n",
       "2017-12-06  133.330002    134.000000  134.289993  132.910004   14641730   \n",
       "2017-12-05  133.479996    133.649994  133.990005  132.779999   12684800   \n",
       "2017-12-04  133.009995    133.770004  134.000000  131.929993   17818980   \n",
       "\n",
       "               delta  \n",
       "date                  \n",
       "2017-12-08  0.829987  \n",
       "2017-12-07  0.679993  \n",
       "2017-12-06 -0.669998  \n",
       "2017-12-05 -0.169998  \n",
       "2017-12-04 -0.760010  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_all = pd.read_csv('gazprom_prices.csv', sep=';')\n",
    "pr_all['date'] =  pd.to_datetime(pr_all.Date, format='%d.%m.%Y')\n",
    "pr_all.drop(['Date'], axis=1, inplace=True)\n",
    "pr_all['Open'] = pr_all['Open'].map(\n",
    "            lambda pr_all: np.float32(pr_all.replace(',', '.')),na_action='ignore')\n",
    "pr_all['ClosingPrice'] = pr_all['ClosingPrice'].map(\n",
    "            lambda pr_all: np.float32(pr_all.replace(',', '.')),na_action='ignore')\n",
    "pr_all['DailyHigh'] = pr_all['DailyHigh'].map(\n",
    "            lambda pr_all: np.float32(pr_all.replace(',', '.')),na_action='ignore')\n",
    "pr_all['DailyLow'] = pr_all['DailyLow'].map(\n",
    "            lambda pr_all: np.float32(pr_all.replace(',', '.')),na_action='ignore')\n",
    "pr_all['delta'] = pr_all.Open - pr_all.ClosingPrice\n",
    "\n",
    "pr_all.set_index('date', inplace=True)\n",
    "pr_all.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Часть 1. Вводная\n",
    "\n",
    "Проведите предобработку текстов: если считаете нужным, выполните токенизацию, приведение к нижнему регистру, лемматизацию и/или стемминг. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Собираем общую таблицу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>delta</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>132.309998</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>132.820007</td>\n",
       "      <td>131.139999</td>\n",
       "      <td>33869650</td>\n",
       "      <td>0.809998</td>\n",
       "      <td>Компания рассчитывает на решение по газовому с...</td>\n",
       "      <td>419.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-08</th>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.300003</td>\n",
       "      <td>133.940002</td>\n",
       "      <td>131.580002</td>\n",
       "      <td>39381960</td>\n",
       "      <td>-0.300003</td>\n",
       "      <td>Как и предполагал “Ъ”, «Газпром», воспользова...</td>\n",
       "      <td>624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>126.400002</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>126.889999</td>\n",
       "      <td>125.970001</td>\n",
       "      <td>18232550</td>\n",
       "      <td>-0.099998</td>\n",
       "      <td>Новая редакция американских санкций ставит по...</td>\n",
       "      <td>835.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>125.959999</td>\n",
       "      <td>125.980003</td>\n",
       "      <td>126.930000</td>\n",
       "      <td>125.529999</td>\n",
       "      <td>19263340</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>Как стало известно “Ъ”, известный на рынке ри...</td>\n",
       "      <td>436.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>127.050003</td>\n",
       "      <td>126.800003</td>\n",
       "      <td>127.470001</td>\n",
       "      <td>126.370003</td>\n",
       "      <td>17308800</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>НОВАТЭК, который через пять лет собирается за...</td>\n",
       "      <td>1272.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open  ClosingPrice   DailyHigh    DailyLow  VolumePcs  \\\n",
       "date                                                                      \n",
       "2017-11-09  132.309998    131.500000  132.820007  131.139999   33869650   \n",
       "2017-11-08  132.000000    132.300003  133.940002  131.580002   39381960   \n",
       "2017-11-01  126.400002    126.500000  126.889999  125.970001   18232550   \n",
       "2017-10-30  125.959999    125.980003  126.930000  125.529999   19263340   \n",
       "2017-10-23  127.050003    126.800003  127.470001  126.370003   17308800   \n",
       "\n",
       "               delta                                               text  \\\n",
       "date                                                                      \n",
       "2017-11-09  0.809998  Компания рассчитывает на решение по газовому с...   \n",
       "2017-11-08 -0.300003   Как и предполагал “Ъ”, «Газпром», воспользова...   \n",
       "2017-11-01 -0.099998   Новая редакция американских санкций ставит по...   \n",
       "2017-10-30 -0.020004   Как стало известно “Ъ”, известный на рынке ри...   \n",
       "2017-10-23  0.250000   НОВАТЭК, который через пять лет собирается за...   \n",
       "\n",
       "               len  \n",
       "date                \n",
       "2017-11-09   419.0  \n",
       "2017-11-08   624.0  \n",
       "2017-11-01   835.0  \n",
       "2017-10-30   436.0  \n",
       "2017-10-23  1272.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data = pr_all.join(df)\n",
    "Data.dropna(axis=0, inplace=True)\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>delta</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1.145000e+03</td>\n",
       "      <td>1145.000000</td>\n",
       "      <td>1145.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>150.018681</td>\n",
       "      <td>149.902970</td>\n",
       "      <td>151.635738</td>\n",
       "      <td>148.193511</td>\n",
       "      <td>4.492943e+07</td>\n",
       "      <td>0.115712</td>\n",
       "      <td>772.908297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>23.464697</td>\n",
       "      <td>23.390248</td>\n",
       "      <td>23.702841</td>\n",
       "      <td>23.090757</td>\n",
       "      <td>2.455151e+07</td>\n",
       "      <td>2.316764</td>\n",
       "      <td>546.978587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>107.230003</td>\n",
       "      <td>107.169998</td>\n",
       "      <td>109.199997</td>\n",
       "      <td>106.500000</td>\n",
       "      <td>7.642310e+06</td>\n",
       "      <td>-12.639999</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>135.889999</td>\n",
       "      <td>135.770004</td>\n",
       "      <td>137.000000</td>\n",
       "      <td>134.500000</td>\n",
       "      <td>2.859430e+07</td>\n",
       "      <td>-1.120003</td>\n",
       "      <td>406.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>144.270004</td>\n",
       "      <td>144.300003</td>\n",
       "      <td>145.889999</td>\n",
       "      <td>142.669998</td>\n",
       "      <td>3.843521e+07</td>\n",
       "      <td>0.110001</td>\n",
       "      <td>584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>157.169998</td>\n",
       "      <td>156.690002</td>\n",
       "      <td>158.630005</td>\n",
       "      <td>155.149994</td>\n",
       "      <td>5.580905e+07</td>\n",
       "      <td>1.310013</td>\n",
       "      <td>1010.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>243.520004</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>247.470001</td>\n",
       "      <td>241.770004</td>\n",
       "      <td>2.024663e+08</td>\n",
       "      <td>13.849998</td>\n",
       "      <td>4120.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Open  ClosingPrice    DailyHigh     DailyLow     VolumePcs  \\\n",
       "count  1145.000000   1145.000000  1145.000000  1145.000000  1.145000e+03   \n",
       "mean    150.018681    149.902970   151.635738   148.193511  4.492943e+07   \n",
       "std      23.464697     23.390248    23.702841    23.090757  2.455151e+07   \n",
       "min     107.230003    107.169998   109.199997   106.500000  7.642310e+06   \n",
       "25%     135.889999    135.770004   137.000000   134.500000  2.859430e+07   \n",
       "50%     144.270004    144.300003   145.889999   142.669998  3.843521e+07   \n",
       "75%     157.169998    156.690002   158.630005   155.149994  5.580905e+07   \n",
       "max     243.520004    244.000000   247.470001   241.770004  2.024663e+08   \n",
       "\n",
       "             delta          len  \n",
       "count  1145.000000  1145.000000  \n",
       "mean      0.115712   772.908297  \n",
       "std       2.316764   546.978587  \n",
       "min     -12.639999    85.000000  \n",
       "25%      -1.120003   406.000000  \n",
       "50%       0.110001   584.000000  \n",
       "75%       1.310013  1010.000000  \n",
       "max      13.849998  4120.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.67 s, sys: 3.18 s, total: 4.85 s\n",
      "Wall time: 17min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "from pymystem3 import Mystem\n",
    "\n",
    "def lemma(text):\n",
    "    text = text.replace('\\xa0', ' ')\n",
    "    try:\n",
    "        return \"\".join(Mystem().lemmatize(text)).strip()  \n",
    "    except:\n",
    "        return \" \"\n",
    "\n",
    "Data['lem_text'] = Data.text.apply(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>delta</th>\n",
       "      <th>text</th>\n",
       "      <th>len</th>\n",
       "      <th>lem_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-11-09</th>\n",
       "      <td>132.309998</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>132.820007</td>\n",
       "      <td>131.139999</td>\n",
       "      <td>33869650</td>\n",
       "      <td>0.809998</td>\n",
       "      <td>Компания рассчитывает на решение по газовому с...</td>\n",
       "      <td>419.0</td>\n",
       "      <td>компания рассчитывать на решение по газовый сп...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-08</th>\n",
       "      <td>132.000000</td>\n",
       "      <td>132.300003</td>\n",
       "      <td>133.940002</td>\n",
       "      <td>131.580002</td>\n",
       "      <td>39381960</td>\n",
       "      <td>-0.300003</td>\n",
       "      <td>Как и предполагал “Ъ”, «Газпром», воспользова...</td>\n",
       "      <td>624.0</td>\n",
       "      <td>как и предполагать “Ъ”, «газпром», воспользова...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-01</th>\n",
       "      <td>126.400002</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>126.889999</td>\n",
       "      <td>125.970001</td>\n",
       "      <td>18232550</td>\n",
       "      <td>-0.099998</td>\n",
       "      <td>Новая редакция американских санкций ставит по...</td>\n",
       "      <td>835.0</td>\n",
       "      <td>новый редакция американский санкция ставить по...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-30</th>\n",
       "      <td>125.959999</td>\n",
       "      <td>125.980003</td>\n",
       "      <td>126.930000</td>\n",
       "      <td>125.529999</td>\n",
       "      <td>19263340</td>\n",
       "      <td>-0.020004</td>\n",
       "      <td>Как стало известно “Ъ”, известный на рынке ри...</td>\n",
       "      <td>436.0</td>\n",
       "      <td>как становиться известно “Ъ”, известный на рын...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-10-23</th>\n",
       "      <td>127.050003</td>\n",
       "      <td>126.800003</td>\n",
       "      <td>127.470001</td>\n",
       "      <td>126.370003</td>\n",
       "      <td>17308800</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>НОВАТЭК, который через пять лет собирается за...</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>новатэк, который через пять год собираться зап...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open  ClosingPrice   DailyHigh    DailyLow  VolumePcs  \\\n",
       "date                                                                      \n",
       "2017-11-09  132.309998    131.500000  132.820007  131.139999   33869650   \n",
       "2017-11-08  132.000000    132.300003  133.940002  131.580002   39381960   \n",
       "2017-11-01  126.400002    126.500000  126.889999  125.970001   18232550   \n",
       "2017-10-30  125.959999    125.980003  126.930000  125.529999   19263340   \n",
       "2017-10-23  127.050003    126.800003  127.470001  126.370003   17308800   \n",
       "\n",
       "               delta                                               text  \\\n",
       "date                                                                      \n",
       "2017-11-09  0.809998  Компания рассчитывает на решение по газовому с...   \n",
       "2017-11-08 -0.300003   Как и предполагал “Ъ”, «Газпром», воспользова...   \n",
       "2017-11-01 -0.099998   Новая редакция американских санкций ставит по...   \n",
       "2017-10-30 -0.020004   Как стало известно “Ъ”, известный на рынке ри...   \n",
       "2017-10-23  0.250000   НОВАТЭК, который через пять лет собирается за...   \n",
       "\n",
       "               len                                           lem_text  \n",
       "date                                                                   \n",
       "2017-11-09   419.0  компания рассчитывать на решение по газовый сп...  \n",
       "2017-11-08   624.0  как и предполагать “Ъ”, «газпром», воспользова...  \n",
       "2017-11-01   835.0  новый редакция американский санкция ставить по...  \n",
       "2017-10-30   436.0  как становиться известно “Ъ”, известный на рын...  \n",
       "2017-10-23  1272.0  новатэк, который через пять год собираться зап...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = Data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D['miller_count'] = D.lem_text.map(\n",
    "    lambda text: text.count('миллер') if text else 0,\n",
    "    na_action='ignore'\n",
    ")\n",
    "D['sever_count'] = D.lem_text.map(\n",
    "    lambda text: text.count('северный поток') if text else 0,\n",
    "    na_action='ignore'\n",
    ")\n",
    "D['turk_count'] = D.lem_text.map(\n",
    "    lambda text: text.count('турецкий поток') if text else 0,\n",
    "    na_action='ignore'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ответьте на следующие вопросы:\n",
    "\n",
    "    1.Есть ли корреляция между средней длинной текста за день и ценой закрытия?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>ClosingPrice</th>\n",
       "      <th>DailyHigh</th>\n",
       "      <th>DailyLow</th>\n",
       "      <th>VolumePcs</th>\n",
       "      <th>delta</th>\n",
       "      <th>len</th>\n",
       "      <th>miller_count</th>\n",
       "      <th>sever_count</th>\n",
       "      <th>turk_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Open</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995115</td>\n",
       "      <td>0.998069</td>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.371362</td>\n",
       "      <td>0.081451</td>\n",
       "      <td>0.014575</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.037291</td>\n",
       "      <td>-0.062884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClosingPrice</th>\n",
       "      <td>0.995115</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997728</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.376791</td>\n",
       "      <td>-0.017338</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.035715</td>\n",
       "      <td>-0.061107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DailyHigh</th>\n",
       "      <td>0.998069</td>\n",
       "      <td>0.997728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996902</td>\n",
       "      <td>0.396443</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>0.015082</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.036612</td>\n",
       "      <td>-0.061706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DailyLow</th>\n",
       "      <td>0.997341</td>\n",
       "      <td>0.997670</td>\n",
       "      <td>0.996902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.346697</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>0.037763</td>\n",
       "      <td>-0.059570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VolumePcs</th>\n",
       "      <td>0.371362</td>\n",
       "      <td>0.376791</td>\n",
       "      <td>0.396443</td>\n",
       "      <td>0.346697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.042877</td>\n",
       "      <td>0.076835</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.100423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>delta</th>\n",
       "      <td>0.081451</td>\n",
       "      <td>-0.017338</td>\n",
       "      <td>0.035520</td>\n",
       "      <td>0.028728</td>\n",
       "      <td>-0.042877</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>-0.012564</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>-0.019967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>len</th>\n",
       "      <td>0.014575</td>\n",
       "      <td>0.012376</td>\n",
       "      <td>0.015082</td>\n",
       "      <td>0.010711</td>\n",
       "      <td>0.076835</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.081808</td>\n",
       "      <td>0.058477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>miller_count</th>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.008110</td>\n",
       "      <td>0.007792</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>0.007320</td>\n",
       "      <td>-0.012564</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.164734</td>\n",
       "      <td>-0.016549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sever_count</th>\n",
       "      <td>0.037291</td>\n",
       "      <td>0.035715</td>\n",
       "      <td>0.036612</td>\n",
       "      <td>0.037763</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>0.081808</td>\n",
       "      <td>0.164734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.075493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>turk_count</th>\n",
       "      <td>-0.062884</td>\n",
       "      <td>-0.061107</td>\n",
       "      <td>-0.061706</td>\n",
       "      <td>-0.059570</td>\n",
       "      <td>-0.100423</td>\n",
       "      <td>-0.019967</td>\n",
       "      <td>0.058477</td>\n",
       "      <td>-0.016549</td>\n",
       "      <td>0.075493</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Open  ClosingPrice  DailyHigh  DailyLow  VolumePcs  \\\n",
       "Open          1.000000      0.995115   0.998069  0.997341   0.371362   \n",
       "ClosingPrice  0.995115      1.000000   0.997728  0.997670   0.376791   \n",
       "DailyHigh     0.998069      0.997728   1.000000  0.996902   0.396443   \n",
       "DailyLow      0.997341      0.997670   0.996902  1.000000   0.346697   \n",
       "VolumePcs     0.371362      0.376791   0.396443  0.346697   1.000000   \n",
       "delta         0.081451     -0.017338   0.035520  0.028728  -0.042877   \n",
       "len           0.014575      0.012376   0.015082  0.010711   0.076835   \n",
       "miller_count  0.006844      0.008110   0.007792  0.008442   0.007320   \n",
       "sever_count   0.037291      0.035715   0.036612  0.037763  -0.011082   \n",
       "turk_count   -0.062884     -0.061107  -0.061706 -0.059570  -0.100423   \n",
       "\n",
       "                 delta       len  miller_count  sever_count  turk_count  \n",
       "Open          0.081451  0.014575      0.006844     0.037291   -0.062884  \n",
       "ClosingPrice -0.017338  0.012376      0.008110     0.035715   -0.061107  \n",
       "DailyHigh     0.035520  0.015082      0.007792     0.036612   -0.061706  \n",
       "DailyLow      0.028728  0.010711      0.008442     0.037763   -0.059570  \n",
       "VolumePcs    -0.042877  0.076835      0.007320    -0.011082   -0.100423  \n",
       "delta         1.000000  0.022667     -0.012564     0.017115   -0.019967  \n",
       "len           0.022667  1.000000      0.148300     0.081808    0.058477  \n",
       "miller_count -0.012564  0.148300      1.000000     0.164734   -0.016549  \n",
       "sever_count   0.017115  0.081808      0.164734     1.000000    0.075493  \n",
       "turk_count   -0.019967  0.058477     -0.016549     0.075493    1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CorrKoef = D.corr()\n",
    "CorrKoef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Судя по коэффициенту корреляции длинна текста не коррелирует ни с ценой закрытия, ни, даже с дельтой за день."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2.Есть ли корреляция между количеством упоминаний Алексея Миллера и ценой закрытия? Учтите разные варианты написания имени."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.Упоминаний какого газопровода в статьях больше:\n",
    "        \"северный поток\"\n",
    "        \"турецкий поток\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    4.О каких санкциях пишут в статьях?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_texts(texts, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        for text in texts:\n",
    "            f.write(\"{}\\n\".format(\n",
    "                text.replace('\\n', ' ').replace('\\r', '').replace('\\t', ' ')\n",
    "            ))\n",
    "\n",
    "save_texts(D.text, 'n_texts.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to find image 'inemo/syntaxnet_rus:latest' locally\n",
      "latest: Pulling from inemo/syntaxnet_rus\n",
      "7dcf5a444392: Pulling fs layer\n",
      "759aa75f3cee: Pulling fs layer\n",
      "3fa871dc8a2b: Pulling fs layer\n",
      "224c42ae46e7: Pulling fs layer\n",
      "db0093dc4b3e: Pulling fs layer\n",
      "442196259211: Pulling fs layer\n",
      "92cc81038f16: Pulling fs layer\n",
      "0c381ee12dcf: Pulling fs layer\n",
      "19ccddee82d3: Pulling fs layer\n",
      "49a4ba5a54b7: Pulling fs layer\n",
      "d639ba646fe3: Pulling fs layer\n",
      "7cb3e0bdd6ac: Pulling fs layer\n",
      "dbf2005010d3: Pulling fs layer\n",
      "b36cc2eaa89d: Pulling fs layer\n",
      "6662b081245f: Pulling fs layer\n",
      "71b3b98bae00: Pulling fs layer\n",
      "a852d3aa1a39: Pulling fs layer\n",
      "afd97fa0ba3d: Pulling fs layer\n",
      "c41a234e15ed: Pulling fs layer\n",
      "991024d8d6c4: Pulling fs layer\n",
      "0534e283426e: Pulling fs layer\n",
      "7cb3e0bdd6ac: Waiting\n",
      "dbf2005010d3: Waiting\n",
      "b36cc2eaa89d: Waiting\n",
      "224c42ae46e7: Waiting\n",
      "6662b081245f: Waiting\n",
      "db0093dc4b3e: Waiting\n",
      "71b3b98bae00: Waiting\n",
      "442196259211: Waiting\n",
      "92cc81038f16: Waiting\n",
      "0c381ee12dcf: Waiting\n",
      "49a4ba5a54b7: Waiting\n",
      "19ccddee82d3: Waiting\n",
      "a852d3aa1a39: Waiting\n",
      "d639ba646fe3: Waiting\n",
      "c41a234e15ed: Waiting\n",
      "afd97fa0ba3d: Waiting\n",
      "0534e283426e: Waiting\n",
      "759aa75f3cee: Download complete\n",
      "3fa871dc8a2b: Verifying Checksum\n",
      "3fa871dc8a2b: Download complete\n",
      "224c42ae46e7: Download complete\n",
      "442196259211: Verifying Checksum\n",
      "442196259211: Download complete\n",
      "7dcf5a444392: Verifying Checksum\n",
      "7dcf5a444392: Download complete\n",
      "92cc81038f16: Download complete\n",
      "0c381ee12dcf: Download complete\n",
      "7dcf5a444392: Pull complete\n",
      "759aa75f3cee: Pull complete\n",
      "3fa871dc8a2b: Pull complete\n",
      "224c42ae46e7: Pull complete\n",
      "49a4ba5a54b7: Verifying Checksum\n",
      "49a4ba5a54b7: Download complete\n",
      "d639ba646fe3: Verifying Checksum\n",
      "d639ba646fe3: Download complete\n",
      "19ccddee82d3: Verifying Checksum\n",
      "19ccddee82d3: Download complete\n",
      "db0093dc4b3e: Verifying Checksum\n",
      "db0093dc4b3e: Download complete\n",
      "db0093dc4b3e: Pull complete\n",
      "442196259211: Pull complete\n",
      "92cc81038f16: Pull complete\n",
      "0c381ee12dcf: Pull complete\n",
      "19ccddee82d3: Pull complete\n",
      "49a4ba5a54b7: Pull complete\n",
      "d639ba646fe3: Pull complete\n",
      "7cb3e0bdd6ac: Verifying Checksum\n",
      "7cb3e0bdd6ac: Download complete\n",
      "dbf2005010d3: Verifying Checksum\n",
      "dbf2005010d3: Download complete\n",
      "71b3b98bae00: Verifying Checksum\n",
      "71b3b98bae00: Download complete\n",
      "7cb3e0bdd6ac: Pull complete\n",
      "b36cc2eaa89d: Verifying Checksum\n",
      "b36cc2eaa89d: Download complete\n",
      "6662b081245f: Verifying Checksum\n",
      "6662b081245f: Download complete\n",
      "dbf2005010d3: Pull complete\n",
      "c41a234e15ed: Download complete\n",
      "991024d8d6c4: Verifying Checksum\n",
      "991024d8d6c4: Download complete\n",
      "b36cc2eaa89d: Pull complete\n",
      "0534e283426e: Verifying Checksum\n",
      "0534e283426e: Download complete\n",
      "6662b081245f: Pull complete\n",
      "71b3b98bae00: Pull complete\n",
      "a852d3aa1a39: Verifying Checksum\n",
      "a852d3aa1a39: Download complete\n",
      "a852d3aa1a39: Pull complete\n",
      "afd97fa0ba3d: Verifying Checksum\n",
      "afd97fa0ba3d: Download complete\n",
      "afd97fa0ba3d: Pull complete\n",
      "c41a234e15ed: Pull complete\n",
      "991024d8d6c4: Pull complete\n",
      "0534e283426e: Pull complete\n",
      "Digest: sha256:cf8e7ca54556946edec3ea377d49c154c5e02a4fe7f8ba60ff75c6e7a7e5b8c2\n",
      "Status: Downloaded newer image for inemo/syntaxnet_rus:latest\n",
      "2017-12-30 19:38:30.960127: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-12-30 19:38:30.960176: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-12-30 19:38:30.960199: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-12-30 19:38:30.986506: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2017-12-30 19:38:30.986940: I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.morphology-set input(1).token.morphology-set input(2).token.morphology-set input(3).token.morphology-set stack.token.morphology-set stack.child(1).token.morphology-set stack.child(1).sibling(-1).token.morphology-set stack.child(-1).token.morphology-set stack.child(-1).sibling(1).token.morphology-set stack.child(2).token.morphology-set stack.child(-2).token.morphology-set stack(1).token.morphology-set stack(1).child(1).token.morphology-set stack(1).child(1).sibling(-1).token.morphology-set stack(1).child(-1).token.morphology-set stack(1).child(-1).sibling(1).token.morphology-set stack(1).child(2).token.morphology-set stack(1).child(-2).token.morphology-set stack(2).token.morphology-set stack(3).token.morphology-set; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "2017-12-30 19:38:30.987218: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;morphology;tags;words\n",
      "2017-12-30 19:38:30.987365: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;32;64\n",
      "2017-12-30 19:38:30.990834: I syntaxnet/term_frequency_map.cc:101] Loaded 66 terms from ./syntaxnet/models/Russian-SynTagRus/morphology-map.\n",
      "2017-12-30 19:38:30.992395: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "2017-12-30 19:38:31.012949: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-12-30 19:38:31.012994: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-12-30 19:38:31.013015: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-12-30 19:38:31.043093: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2017-12-30 19:38:31.043503: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-tag input(-2).pred-tag input(-3).pred-tag input(-4).pred-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "2017-12-30 19:38:31.043541: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "2017-12-30 19:38:31.043576: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n",
      "2017-12-30 19:38:31.050304: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-12-30 19:38:31.050352: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-12-30 19:38:31.050375: W external/org_tensorflow/tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-30 19:38:31.076289: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2017-12-30 19:38:31.076609: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-morph-tag input(-2).pred-morph-tag input(-3).pred-morph-tag input(-4).pred-morph-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "2017-12-30 19:38:31.076641: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "2017-12-30 19:38:31.076662: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n",
      "2017-12-30 19:38:31.649906: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2017-12-30 19:38:31.662432: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "2017-12-30 19:38:31.666465: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2017-12-30 19:38:33.111201: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [12 20 20 20] domain_sizes: [    37     66     33 103475]\n",
      "INFO:tensorflow:Restoring parameters from ./syntaxnet/models/Russian-SynTagRus/parser-params\n",
      "2017-12-30 19:38:34.427664: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2017-12-30 19:38:34.427722: I syntaxnet/embedding_feature_extractor.cc:35] Features: stack.child(1).label stack.child(1).sibling(-1).label stack.child(-1).label stack.child(-1).sibling(1).label stack.child(2).label stack.child(-2).label stack(1).child(1).label stack(1).child(1).sibling(-1).label stack(1).child(-1).label stack(1).child(-1).sibling(1).label stack(1).child(2).label stack(1).child(-2).label; input.token.morphology-set input(1).token.morphology-set input(2).token.morphology-set input(3).token.morphology-set stack.token.morphology-set stack.child(1).token.morphology-set stack.child(1).sibling(-1).token.morphology-set stack.child(-1).token.morphology-set stack.child(-1).sibling(1).token.morphology-set stack.child(2).token.morphology-set stack.child(-2).token.morphology-set stack(1).token.morphology-set stack(1).child(1).token.morphology-set stack(1).child(1).sibling(-1).token.morphology-set stack(1).child(-1).token.morphology-set stack(1).child(-1).sibling(1).token.morphology-set stack(1).child(2).token.morphology-set stack(1).child(-2).token.morphology-set stack(2).token.morphology-set stack(3).token.morphology-set; input.token.tag input(1).token.tag input(2).token.tag input(3).token.tag stack.token.tag stack.child(1).token.tag stack.child(1).sibling(-1).token.tag stack.child(-1).token.tag stack.child(-1).sibling(1).token.tag stack.child(2).token.tag stack.child(-2).token.tag stack(1).token.tag stack(1).child(1).token.tag stack(1).child(1).sibling(-1).token.tag stack(1).child(-1).token.tag stack(1).child(-1).sibling(1).token.tag stack(1).child(2).token.tag stack(1).child(-2).token.tag stack(2).token.tag stack(3).token.tag; input.token.word input(1).token.word input(2).token.word input(3).token.word stack.token.word stack.child(1).token.word stack.child(1).sibling(-1).token.word stack.child(-1).token.word stack.child(-1).sibling(1).token.word stack.child(2).token.word stack.child(-2).token.word stack(1).token.word stack(1).child(1).token.word stack(1).child(1).sibling(-1).token.word stack(1).child(-1).token.word stack(1).child(-1).sibling(1).token.word stack(1).child(2).token.word stack(1).child(-2).token.word stack(2).token.word stack(3).token.word \n",
      "2017-12-30 19:38:34.427761: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: labels;morphology;tags;words\n",
      "2017-12-30 19:38:34.427793: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 32;32;32;64\n",
      "2017-12-30 19:38:34.429770: I syntaxnet/term_frequency_map.cc:101] Loaded 66 terms from ./syntaxnet/models/Russian-SynTagRus/morphology-map.\n",
      "2017-12-30 19:38:34.430964: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "2017-12-30 19:38:35.045176: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [8 8 4 8 8 8 8 4 8] domain_sizes: [     7  18750      5   8502   8502   7249   7249    449 103475]\n",
      "2017-12-30 19:38:35.105890: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Building training network with parameters: feature_sizes: [8 8 4 8 8 8 8 4 8] domain_sizes: [     7  18750      5   8502   8502   7249   7249     34 103475]\n",
      "INFO:tensorflow:Restoring parameters from ./syntaxnet/models/Russian-SynTagRus/morpher-params\n",
      "2017-12-30 19:38:36.773467: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2017-12-30 19:38:36.773522: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-morph-tag input(-2).pred-morph-tag input(-3).pred-morph-tag input(-4).pred-morph-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "2017-12-30 19:38:36.773561: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "2017-12-30 19:38:36.773591: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12-30 19:38:37.121009: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2017-12-30 19:38:37.437652: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Restoring parameters from ./syntaxnet/models/Russian-SynTagRus/tagger-params\n",
      "2017-12-30 19:38:37.624885: I syntaxnet/term_frequency_map.cc:101] Loaded 31 terms from ./syntaxnet/models/Russian-SynTagRus/tag-map.\n",
      "2017-12-30 19:38:37.625814: I syntaxnet/term_frequency_map.cc:101] Loaded 34 terms from ./syntaxnet/models/Russian-SynTagRus/label-map.\n",
      "2017-12-30 19:38:37.625852: I syntaxnet/embedding_feature_extractor.cc:35] Features: input.capitalization input(1).capitalization input(2).capitalization input(3).capitalization input(-1).capitalization input(-2).capitalization input(-3).capitalization input(-4).capitalization; input.token.char-ngram input(1).token.char-ngram input(2).token.char-ngram input(3).token.char-ngram input(-1).token.char-ngram input(-2).token.char-ngram input(-3).token.char-ngram input(-4).token.char-ngram; input.digit input.hyphen input.token.punctuation-amount input.token.quote; input.token.prefix(length=2) input(1).token.prefix(length=2) input(2).token.prefix(length=2) input(3).token.prefix(length=2) input(-1).token.prefix(length=2) input(-2).token.prefix(length=2) input(-3).token.prefix(length=2) input(-4).token.prefix(length=2); input.token.prefix(length=3) input(1).token.prefix(length=3) input(2).token.prefix(length=3) input(3).token.prefix(length=3) input(-1).token.prefix(length=3) input(-2).token.prefix(length=3) input(-3).token.prefix(length=3) input(-4).token.prefix(length=3); input.token.suffix(length=2) input(1).token.suffix(length=2) input(2).token.suffix(length=2) input(3).token.suffix(length=2) input(-1).token.suffix(length=2) input(-2).token.suffix(length=2) input(-3).token.suffix(length=2) input(-4).token.suffix(length=2); input.token.suffix(length=3) input(1).token.suffix(length=3) input(2).token.suffix(length=3) input(3).token.suffix(length=3) input(-1).token.suffix(length=3) input(-2).token.suffix(length=3) input(-3).token.suffix(length=3) input(-4).token.suffix(length=3); input(-1).pred-tag input(-2).pred-tag input(-3).pred-tag input(-4).pred-tag; input.token.word input(1).token.word input(2).token.word input(3).token.word input(-1).token.word input(-2).token.word input(-3).token.word input(-4).token.word\n",
      "2017-12-30 19:38:37.625907: I syntaxnet/embedding_feature_extractor.cc:36] Embedding names: capitalization;char_ngram;other;prefix2;prefix3;suffix2;suffix3;tags;words\n",
      "2017-12-30 19:38:37.625933: I syntaxnet/embedding_feature_extractor.cc:37] Embedding dims: 2;16;8;16;16;16;16;16;64\n",
      "2017-12-30 19:38:37.949628: I syntaxnet/term_frequency_map.cc:101] Loaded 18749 terms from ./syntaxnet/models/Russian-SynTagRus/char-ngram-map.\n",
      "2017-12-30 19:38:39.208404: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "2017-12-30 19:38:39.943429: I syntaxnet/term_frequency_map.cc:101] Loaded 103473 terms from ./syntaxnet/models/Russian-SynTagRus/word-map.\n",
      "INFO:tensorflow:Processed 1024 documents\n",
      "INFO:tensorflow:Processed 121 documents\n",
      "INFO:tensorflow:Processed 1024 documents\n",
      "INFO:tensorflow:Total processed documents: 1145\n",
      "INFO:tensorflow:num correct tokens: 0\n",
      "INFO:tensorflow:total tokens: 118352\n",
      "INFO:tensorflow:Seconds elapsed in evaluation: 145.17, eval metric: 0.00%\n",
      "INFO:tensorflow:Processed 121 documents\n"
     ]
    }
   ],
   "source": [
    "! cat ./n_texts.txt | docker run --rm -i inemo/syntaxnet_rus > news_texts.conll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Часть 2. Классификационная\n",
    "\n",
    "Вам предстоит решить следующую задачу: по текстам новостей за день определить, вырастет или понизится цена закрытия. Для этого:\n",
    "\n",
    "    бинаризуйте признак \"цена закрытия\": новый признак ClosingPrice_bin равен 1, если по сравнению со вчера цена не упала, и 0 – в обратном случаея;\n",
    "    составьте бучающее и тестовое множество: данные до начала 2016 года используются для обучения, данные с 2016 года и позже – для тестирования.\n",
    "\n",
    "Таким образом, в каждлый момент времени мы знаем:\n",
    "\n",
    "    ClosingPrice_bin – бинарый целевой признак\n",
    "    слова из статей, опубликованных в этот день – объясняющие признаки\n",
    "\n",
    "В этой части задания вам нужно сделать baseline алгоритм и попытаться его улучшить в следующей части.\n",
    "\n",
    "Используйте любой известный вам алгоритм классификации текстов для того, Используйте $tf-idf$ преобразование, сингулярное разложение, нормировку признакого пространства и любые другие техники обработки данных, которые вы считаете нужным. Используйте accuracy и F-measure для оценки качества классификации. Покажите, как $tf-idf$ преобразование или сингулярное разложение или любая другая использованная вами техника влияет на качество классификации. Если у выбранного вами алгоритма есть гиперпараметры (например, $\\alpha$ в преобразовании Лапласа для метода наивного Байеса), покажите, как изменение гиперпараметра влияет на качество классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Часть 3. Творческая\n",
    "\n",
    "Придумайте и попытайтесь сделать еще что-нибудь, чтобы улучшить качество классификации. Направления развития:\n",
    "\n",
    "    Морфологический признаки:\n",
    "        использовать в качестве признаков только существительные или только именованные сущности;\n",
    "    Модели скрытых тем:\n",
    "        использовать в качестве признаков скрытые темы;\n",
    "        использовать в качестве признаков динамические скрытые темы пример тут: (https://github.com/RaRe-Technologies/gensim/blob/develop/docs/notebooks/dtm_example.ipynb)\n",
    "    Синтаксические признаки:\n",
    "        использовать SOV-тройки в качестве признаков\n",
    "        кластеризовать SOV-тройки по эмбеддингам глаголов (обученные word2vec модели можно скачать отсюда: (http://rusvectores.org/ru/models/) и использовать только центроиды кластеров в качестве признаков\n",
    "    что-нибудь еще\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
