{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/c/titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! pip install c:\\1\\xgboost-0.6-cp36-cp36m-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!conda install -y -c conda-forge xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загружаем данные из файлов\n",
    "train = pd.read_csv('./titanic/train.csv')\n",
    "test = pd.read_csv('./titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Заполняем пропуски в данных медианными \n",
    "# значениями факторов на обучающей выборке\n",
    "train_median = train.median()\n",
    "train_imp = train.fillna(train_median)\n",
    "test_imp = test.fillna(train_median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Бинаризуем категориальные признаки\n",
    "CATEGORY_COL = ['Sex', 'Pclass', 'Embarked']\n",
    "train_dummies = pd.get_dummies(train_imp, columns=CATEGORY_COL, drop_first=True)\n",
    "test_dummies = pd.get_dummies(test_imp, columns=CATEGORY_COL, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived                                               Name  \\\n",
       "0            1         0                            Braund, Mr. Owen Harris   \n",
       "1            2         1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3         1                             Heikkinen, Miss. Laina   \n",
       "3            4         1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5         0                           Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare Cabin  Sex_male  Pclass_2  \\\n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN         1         0   \n",
       "1  38.0      1      0          PC 17599  71.2833   C85         0         0   \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN         0         0   \n",
       "3  35.0      1      0            113803  53.1000  C123         0         0   \n",
       "4  35.0      0      0            373450   8.0500   NaN         1         0   \n",
       "\n",
       "   Pclass_3  Embarked_Q  Embarked_S  \n",
       "0         1           0           1  \n",
       "1         0           0           0  \n",
       "2         1           0           1  \n",
       "3         0           0           1  \n",
       "4         1           0           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Удаляем лишние столбцы\n",
    "DROP_COL = ['PassengerId', 'Name', 'Ticket', 'Cabin']\n",
    "TARGET_COL = 'Survived'\n",
    "X_train = train_dummies.drop(DROP_COL + [TARGET_COL], axis=1)\n",
    "y_train = train_dummies[TARGET_COL]\n",
    "X_test = test_dummies.drop(DROP_COL, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost\n",
    "\n",
    "**Основные параметры**\n",
    "\n",
    "| Параметр          | Тип                | Описание                                                                                                                                     | Диапазон значений      |\n",
    "|-------------------|--------------------|----------------------------------------------------------------------------------------------------------------------------------------------|------------------------|\n",
    "| **max_depth**         | int                | Максимальная глубина каждого дерева                                                                                                          | 3-10                   |\n",
    "| **learning_rate**     | float              | Шаг градиентного бустинга                                                                                                                    | 0.01-0.2               |\n",
    "| **n_estimators**      | int                | Размер ансамбля                                                                                                                              | 100-1000               |\n",
    "| **objective**         | string or callable | Оптмизируемый функционал. В отличие от метрики качества, должен быть всюду дифференцируем                                                    |                        |\n",
    "| **booster**           | string             | Какой бустинг использовать                                                                                                                   | [gbtree,gblinear,dart] |\n",
    "| **nthread**           | int                | Количество потоков, в котором будет обучаться XGBoost                                                                                        |                        |\n",
    "| **n_jobs**            | int                | -//-                                                                                                                                         |                        |\n",
    "| **gamma**             | float              |  Минимальный прирост качества функционала ошибки, при котором лист дерева будет поделён на поддеревья. Минимальный критерий ветвления дерева |                        |\n",
    "| **min_child_weight**  | float              | Минимальная сумма весов в листе дерева для того, чтобы его не выкинуть                                                                       |                        |\n",
    "| **max_delta_step**    | int                | Максимальный шаг, с которым можно обновлять веса деревьев                                                                                    |                        |\n",
    "| **subsample**         | float              | На какой случайной доли обучающей выборки будет обучаться каждое дерево                                                                      |                        |\n",
    "| **colsample_bytree**  | float              | На какой случайной доли признаков будет обучаться каждое дерево                                                                              | [0.5-1]                |\n",
    "| **colsample_bylevel** | float              | Какая доля признаков пойдёт в каждое поддерево                                                                                               |                        |\n",
    "| **reg_alpha**         | float              | L1-регуляризация для листьев дерева                                                                                                          |                        |\n",
    "| **reg_lambda**        | float              | L2-регуляризация для листьев дерева                                                                                                          |                        |\n",
    "| **scale_pos_weight**  | float              | Какой вес придадим второму классу объектов (1) по сравнению с первым (0). Используется при сильно несбалансированной выборке                 |                        |\n",
    "| **base_score**        | float              |  До какого скора объекты будут отнесену к первому классу (0) и с какого ко второму (1). По умолчанию 0.5. Обычно не тюнят                    |                        |\n",
    "| **seed**              | int                | Начальная точка для генератора случайных чисел                                                                                               |                        |\n",
    "| **random_state**      | int                | -//-                                                                                                                                         |                        |\n",
    "| **missing**           | float (optional)   | Что принимать за пропущенные значения. По умолчанию np.nan.                                                                                  |                        |\n",
    "| **silent**            | boolean            | Если True, то выводить всю информацию об обучении                                                                                            |                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Упражнение 1\n",
    "Используя текущее описание параметров и предыдущее упражнение, произведите базовый подбор параметров XGBoost'a, используя метрику **AUC**. Сравните полученное качество (**AUC**) с полученным ранее на RandomForest и GradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "[CV] min_samples_split=2, n_estimators=1 .............................\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter min_samples_split for estimator XGBClassifier. Check the list of available parameters with `estimator.get_params().keys()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d2e3107febc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mroc_scorer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m# запуск гридсёча\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 638\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    639\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mset_params\u001b[1;34m(self, **params)\u001b[0m\n\u001b[0;32m    281\u001b[0m                                      \u001b[1;34m'Check the list of available parameters '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m                                      \u001b[1;34m'with `estimator.get_params().keys()`.'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 283\u001b[1;33m                                      (key, self.__class__.__name__))\n\u001b[0m\u001b[0;32m    284\u001b[0m                 \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    285\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid parameter min_samples_split for estimator XGBClassifier. Check the list of available parameters with `estimator.get_params().keys()`."
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, make_scorer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = xgboost.XGBClassifier()\n",
    "\n",
    "#clf = RandomForestClassifier()\n",
    "## TODO: ваш GridSearch\n",
    "#...\n",
    "\n",
    "\n",
    "\n",
    "params_grid = { # параметры для RandomForest, которые будем тюнить\n",
    "    'n_estimators': [1, 2, 3, 10, 35],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# функция, скор которой будет выводиться в гридсёче\n",
    "roc_scorer = make_scorer(lambda y_true, y_pred: roc_auc_score(y_true, y_pred[:, 1]), needs_proba=True)\n",
    "kf = KFold(n_splits=4, shuffle=True)\n",
    "gs = GridSearchCV(clf, param_grid=params_grid, verbose=5, scoring=roc_scorer, cv=kf)\n",
    "# запуск гридсёча\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Более умный и последовательный тюнинг\n",
    "Взято [отсюда](https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/). Это наиболее полный и часто используемый мануал для тюнинга XGBoost.\n",
    "**Алгоритм:**\n",
    "1. Choose a relatively high learning rate. Generally a learning rate of 0.1 works but somewhere between 0.05 to 0.3 should work for different problems. Determine the optimum number of trees for this learning rate. XGBoost has a very useful function called as “cv” which performs cross-validation at each boosting iteration and thus returns the optimum number of trees required.\n",
    "2. Tune tree-specific parameters ( max_depth, min_child_weight, gamma, subsample, colsample_bytree) for decided learning rate and number of trees. Note that we can choose different parameters to define a tree and I’ll take up an example here.\n",
    "3. Tune regularization parameters (lambda, alpha) for xgboost which can help reduce model complexity and enhance performance.\n",
    "4. Lower the learning rate and decide the optimal parameters ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 1: Зафиксируем learning_rate и параметры дерева и подберём n_estimators\n",
    "\n",
    "Параметры:\n",
    "\n",
    "* **max_depth**. Как указанов в таблице выше, обычно варьируется в интервале от 3 до 10 (но от задачи к задаче значения могут меняться). В качестве начального значения обычно используют 5\n",
    "* **min_child_weight**. Если выборка сильно несбалансирована, то лучше выбрать значение \"1\". Иначе лучше выбрать значение \"2\" и зафиксировать\n",
    "* **gamma**. Обычно выставляют значение в интервале от 0 до 0.2 и фиксируют. В дальнейшем этот параметр всегда можно затюнить отдельно\n",
    "* **subsample, colsample_bytree**. Выставим 0.8 и зафиксируем. Можно также проварьировать в интервале 0.5-0.9.\n",
    "* **scale_pos_weight**. Выставляется в зафисимости от соотношения классов в выборке и фиксируется"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ones_ratio = y_train[y_train == 1].shape[0] * 1.0 / y_train[y_train == 0].shape[0] # посчитаем соотношение между классами\n",
    "\n",
    "param_grid = {\n",
    "    # параметры ансамбля\n",
    "    'n_estimators': [10, 30, 50, 100, 200, 400, 600, 1000],\n",
    "    'learning_rate': [0.1],\n",
    "    \n",
    "    # параметры дерева\n",
    "    'max_depth': [5],\n",
    "    'min_child_weight': [2],\n",
    "    'gamma': [0.1],\n",
    "    'subsample': [0.8],\n",
    "    'colsample_bytree': [0.8],\n",
    "    'scale_pos_weight': [ones_ratio],\n",
    "    \n",
    "    # параметры регуляризации\n",
    "    'reg_alpha': [0.0],\n",
    "    'reg_lambda': [1.0]\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=4, shuffle=True)\n",
    "\n",
    "clf = xgboost.XGBClassifier()\n",
    "gs = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, verbose=5)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 2. Подбираем параметры дерева\n",
    "* **max_depth** - будем варьировать от 3 до 10 с шагом 2\n",
    "* **min_child_weight** - от 1 до 6 с шагом 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': range(3, 10, 2),\n",
    "    'min_child_weight': range(1, 6, 2)\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params) # в качестве отправной точки возьмём модель с наилучшими параметрами предыдущего шага\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, verbose=5)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 3. Подбираем gamma (критерий создания поддерева)\n",
    "* **gamma** - от 0 до 0.5 с шагом 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-603bf0e6152e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m }\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'gamma': [0.1*i for i in range(6)]\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, verbose=5)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 4. Затюним subsample и colsample_bytree\n",
    "* **subsample** - от 0.5 до 1.0 с шагом 0.1\n",
    "* **colsample_bytree** - от 0.5 до 1.0 с шагом 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-a335c59715e5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m }\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'subsample': [0.5 + 0.1*i for i in range(6)],\n",
    "    'colsample_bytree': [0.5 + 0.1*i for i in range(6)]\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, verbose=5)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 5. Регуляризация\n",
    "* **reg_alpha** [1e-5, 1e-2, 0.1, 1, 100]\n",
    "* **reg_lambda** [1e-5, 1e-2, 0.1, 1, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_params' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-d46a967db744>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m }\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_params' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100],\n",
    "    'reg_lambda': [1e-5, 1e-2, 0.1, 1, 100]\n",
    "}\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "\n",
    "gs = GridSearchCV(clf, param_grid, scoring='roc_auc', cv=cv, verbose=5)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best_params = gs.best_estimator_.get_params()\n",
    "print('Best score (AUC): ', gs.best_score_)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Шаг 6. Learning rate\n",
    "Чем меньше у нас **n_estimators** в ансамбле, тем быстрее нам нужно двигаться с каждым шагом (добавлением нового классификатора), т.е. делать больший **learning_rate**. Обычно **learning rate** варьируют так, чтобы произведение **n_estimators** x **learning_rate** оставалось инвариантным"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\artem\\anaconda3\\envs\\lasagne2.7\\lib\\site-packages\\xgboost-0.6-py2.7.egg\\xgboost\\sklearn.py:171: DeprecationWarning: The nthread parameter is deprecated as of version .6.Please use n_jobs instead.nthread is deprecated.\n",
      "  'nthread is deprecated.', DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best score (AUC): ', 0.92546693812516601)\n",
      "Best params: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'base_score': 0.5,\n",
       " 'booster': 'gbtree',\n",
       " 'colsample_bylevel': 1,\n",
       " 'colsample_bytree': 0.9,\n",
       " 'gamma': 0.4,\n",
       " 'learning_rate': 0.0125,\n",
       " 'max_delta_step': 0,\n",
       " 'max_depth': 3,\n",
       " 'min_child_weight': 1,\n",
       " 'missing': None,\n",
       " 'n_estimators': 800,\n",
       " 'n_jobs': 1,\n",
       " 'nthread': 1,\n",
       " 'objective': 'binary:logistic',\n",
       " 'random_state': 0,\n",
       " 'reg_alpha': 1,\n",
       " 'reg_lambda': 0.01,\n",
       " 'scale_pos_weight': 0.6229508196721312,\n",
       " 'seed': 0,\n",
       " 'silent': True,\n",
       " 'subsample': 0.6}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "clf = xgboost.XGBClassifier(**best_params)\n",
    "best_n_estimators = clf.get_params()['n_estimators'] # возьмём наилучшие значения n_estimators с предыдущего шага\n",
    "best_learning_rate = best_params['learning_rate'] # аналогичная запись\n",
    "invariant_composition = best_n_estimators * best_learning_rate\n",
    "n_estimators_range = [10, 30, 100, 200, 400, 600, 800, 1000]\n",
    "\n",
    "best_score = gs.best_score_ # возьмём наилучшее качество с предыдущего шага\n",
    "\n",
    "for n_estimators in n_estimators_range:\n",
    "    learning_rate = invariant_composition / n_estimators\n",
    "    clf.set_params(n_estimators=n_estimators, learning_rate=learning_rate)\n",
    "    aucs = []\n",
    "    for train_idx, test_idx in cv.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        preds = clf.predict_proba(X_test_fold)\n",
    "        auc = roc_auc_score(y_test_fold, preds[:, 1])\n",
    "        aucs.append(auc)\n",
    "    auc = np.mean(auc)\n",
    "    if auc > best_score:\n",
    "        best_n_estimators = n_estimators\n",
    "        best_learning_rate = learning_rate\n",
    "        best_score = auc\n",
    "        \n",
    "best_params['n_estimators'] = best_n_estimators\n",
    "best_params['learning_rate'] = best_learning_rate\n",
    "\n",
    "print('Best score (AUC): ', best_score)\n",
    "print('Best params: ')\n",
    "best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Выведем важность признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: \"Age\"\tFeature importance: 0.2828\n",
      "Feature: \"SibSp\"\tFeature importance: 0.0719\n",
      "Feature: \"Parch\"\tFeature importance: 0.0415\n",
      "Feature: \"Fare\"\tFeature importance: 0.3659\n",
      "Feature: \"Sex_male\"\tFeature importance: 0.0969\n",
      "Feature: \"Pclass_2\"\tFeature importance: 0.0210\n",
      "Feature: \"Pclass_3\"\tFeature importance: 0.0667\n",
      "Feature: \"Embarked_Q\"\tFeature importance: 0.0102\n",
      "Feature: \"Embarked_S\"\tFeature importance: 0.0431\n"
     ]
    }
   ],
   "source": [
    "for feature_name, feature_importance in zip(X_train.columns, clf.feature_importances_):\n",
    "    print('Feature: \"%s\"\\tFeature importance: %.4f' % (feature_name, feature_importance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt\n",
    "!pip install networkx==1.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.8500000000000001, 'silent': 1, 'scale_pos_weight': 9.5, 'learning_rate': 0.2, 'min_child_weight': 3.0, 'n_estimators': 270.0, 'subsample': 0.9500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 7.0, 'gamma': 0.75}\n",
      "{'status': 'ok', 'loss': 0.9290969899665551}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.6000000000000001, 'silent': 1, 'scale_pos_weight': 8.0, 'learning_rate': 0.5, 'min_child_weight': 4.0, 'n_estimators': 770.0, 'subsample': 0.9500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 7.0, 'gamma': 0.7000000000000001}\n",
      "{'status': 'ok', 'loss': 0.83310433662516103}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.7000000000000001, 'silent': 1, 'scale_pos_weight': 2.0, 'learning_rate': 0.375, 'min_child_weight': 3.0, 'n_estimators': 645.0, 'subsample': 0.8, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 5.0, 'gamma': 0.6000000000000001}\n",
      "{'status': 'ok', 'loss': 0.88182205193699448}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.75, 'silent': 1, 'scale_pos_weight': 1.5, 'learning_rate': 0.07500000000000001, 'min_child_weight': 3.0, 'n_estimators': 145.0, 'subsample': 0.9, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 10.0, 'gamma': 0.6000000000000001}\n",
      "{'status': 'ok', 'loss': 0.8492915414340918}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.5, 'silent': 1, 'scale_pos_weight': 5.5, 'learning_rate': 0.225, 'min_child_weight': 6.0, 'n_estimators': 850.0, 'subsample': 0.9, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 3.0, 'gamma': 0.8}\n",
      "{'status': 'ok', 'loss': 0.86657831737346103}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.9, 'silent': 1, 'scale_pos_weight': 1.0, 'learning_rate': 0.07500000000000001, 'min_child_weight': 2.0, 'n_estimators': 325.0, 'subsample': 0.6000000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 3.0, 'gamma': 0.7000000000000001}\n",
      "{'status': 'ok', 'loss': 0.84181338028169017}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.8, 'silent': 1, 'scale_pos_weight': 3.5, 'learning_rate': 0.35000000000000003, 'min_child_weight': 3.0, 'n_estimators': 645.0, 'subsample': 0.75, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 1.0, 'gamma': 0.9}\n",
      "{'status': 'ok', 'loss': 0.86262541806020077}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 1.0, 'silent': 1, 'scale_pos_weight': 4.0, 'learning_rate': 0.125, 'min_child_weight': 1.0, 'n_estimators': 505.0, 'subsample': 0.65, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 5.0, 'gamma': 0.75}\n",
      "{'status': 'ok', 'loss': 0.87789351851851871}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.6000000000000001, 'silent': 1, 'scale_pos_weight': 4.0, 'learning_rate': 0.375, 'min_child_weight': 4.0, 'n_estimators': 700.0, 'subsample': 0.9500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 9.0, 'gamma': 0.55}\n",
      "{'status': 'ok', 'loss': 0.8678180574555403}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.9500000000000001, 'silent': 1, 'scale_pos_weight': 5.5, 'learning_rate': 0.30000000000000004, 'min_child_weight': 5.0, 'n_estimators': 625.0, 'subsample': 0.8, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 7.0, 'gamma': 0.9500000000000001}\n",
      "{'status': 'ok', 'loss': 0.83410278745644595}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.75, 'silent': 1, 'scale_pos_weight': 5.0, 'learning_rate': 0.17500000000000002, 'min_child_weight': 5.0, 'n_estimators': 505.0, 'subsample': 0.7000000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 2.0, 'gamma': 0.7000000000000001}\n",
      "{'status': 'ok', 'loss': 0.87718023255813959}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.75, 'silent': 1, 'scale_pos_weight': 6.0, 'learning_rate': 0.25, 'min_child_weight': 2.0, 'n_estimators': 400.0, 'subsample': 0.65, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 7.0, 'gamma': 0.8}\n",
      "{'status': 'ok', 'loss': 0.81541434091884912}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.75, 'silent': 1, 'scale_pos_weight': 3.5, 'learning_rate': 0.47500000000000003, 'min_child_weight': 2.0, 'n_estimators': 610.0, 'subsample': 0.65, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 2.0, 'gamma': 0.6000000000000001}\n",
      "{'status': 'ok', 'loss': 0.87587792642140472}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.65, 'silent': 1, 'scale_pos_weight': 4.5, 'learning_rate': 0.35000000000000003, 'min_child_weight': 2.0, 'n_estimators': 400.0, 'subsample': 0.6000000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 7.0, 'gamma': 0.9500000000000001}\n",
      "{'status': 'ok', 'loss': 0.84713187463039619}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.9, 'silent': 1, 'scale_pos_weight': 9.5, 'learning_rate': 0.225, 'min_child_weight': 5.0, 'n_estimators': 835.0, 'subsample': 0.7000000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 4.0, 'gamma': 0.8500000000000001}\n",
      "{'status': 'ok', 'loss': 0.83738785369220148}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.9, 'silent': 1, 'scale_pos_weight': 7.0, 'learning_rate': 0.275, 'min_child_weight': 5.0, 'n_estimators': 790.0, 'subsample': 0.6000000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 5.0, 'gamma': 0.5}\n",
      "{'status': 'ok', 'loss': 0.8491809116809117}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.9500000000000001, 'silent': 1, 'scale_pos_weight': 6.5, 'learning_rate': 0.07500000000000001, 'min_child_weight': 1.0, 'n_estimators': 550.0, 'subsample': 0.9500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 9.0, 'gamma': 0.5}\n",
      "{'status': 'ok', 'loss': 0.8607394366197183}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.5, 'silent': 1, 'scale_pos_weight': 5.0, 'learning_rate': 0.025, 'min_child_weight': 4.0, 'n_estimators': 195.0, 'subsample': 0.5, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 7.0, 'gamma': 0.9}\n",
      "{'status': 'ok', 'loss': 0.85788327526132413}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.7000000000000001, 'silent': 1, 'scale_pos_weight': 7.5, 'learning_rate': 0.325, 'min_child_weight': 3.0, 'n_estimators': 460.0, 'subsample': 0.9, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 5.0, 'gamma': 0.8}\n",
      "{'status': 'ok', 'loss': 0.8025931336742147}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.75, 'silent': 1, 'scale_pos_weight': 3.5, 'learning_rate': 0.35000000000000003, 'min_child_weight': 2.0, 'n_estimators': 350.0, 'subsample': 0.7000000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 9.0, 'gamma': 0.65}\n",
      "{'status': 'ok', 'loss': 0.88165176670923795}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.65, 'silent': 1, 'scale_pos_weight': 8.0, 'learning_rate': 0.42500000000000004, 'min_child_weight': 1.0, 'n_estimators': 985.0, 'subsample': 0.8500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 6.0, 'gamma': 0.8}\n",
      "{'status': 'ok', 'loss': 0.86668928086838537}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.8, 'silent': 1, 'scale_pos_weight': 8.0, 'learning_rate': 0.30000000000000004, 'min_child_weight': 2.0, 'n_estimators': 430.0, 'subsample': 0.55, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 6.0, 'gamma': 0.8500000000000001}\n",
      "{'status': 'ok', 'loss': 0.89497211649110386}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.65, 'silent': 1, 'scale_pos_weight': 6.5, 'learning_rate': 0.42500000000000004, 'min_child_weight': 3.0, 'n_estimators': 200.0, 'subsample': 0.8, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 8.0, 'gamma': 0.8}\n",
      "{'status': 'ok', 'loss': 0.85136300897170469}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.55, 'silent': 1, 'scale_pos_weight': 8.5, 'learning_rate': 0.15000000000000002, 'min_child_weight': 1.0, 'n_estimators': 460.0, 'subsample': 0.75, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 4.0, 'gamma': 1.0}\n",
      "{'status': 'ok', 'loss': 0.84832421340629272}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.7000000000000001, 'silent': 1, 'scale_pos_weight': 7.0, 'learning_rate': 0.25, 'min_child_weight': 2.0, 'n_estimators': 280.0, 'subsample': 1.0, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 6.0, 'gamma': 0.8500000000000001}\n",
      "{'status': 'ok', 'loss': 0.87620607240860404}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.8, 'silent': 1, 'scale_pos_weight': 9.0, 'learning_rate': 0.30000000000000004, 'min_child_weight': 4.0, 'n_estimators': 375.0, 'subsample': 0.5, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 8.0, 'gamma': 0.9}\n",
      "{'status': 'ok', 'loss': 0.88871635610766053}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.7000000000000001, 'silent': 1, 'scale_pos_weight': 6.0, 'learning_rate': 0.42500000000000004, 'min_child_weight': 3.0, 'n_estimators': 105.0, 'subsample': 0.8500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 4.0, 'gamma': 0.75}\n",
      "{'status': 'ok', 'loss': 0.87367476060191518}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.8500000000000001, 'silent': 1, 'scale_pos_weight': 7.5, 'learning_rate': 0.25, 'min_child_weight': 2.0, 'n_estimators': 265.0, 'subsample': 0.55, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 8.0, 'gamma': 0.8}\n",
      "{'status': 'ok', 'loss': 0.87952018212065486}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.8500000000000001, 'silent': 1, 'scale_pos_weight': 10.0, 'learning_rate': 0.2, 'min_child_weight': 3.0, 'n_estimators': 550.0, 'subsample': 1.0, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 6.0, 'gamma': 0.75}\n",
      "{'status': 'ok', 'loss': 0.86157810255977019}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.55, 'silent': 1, 'scale_pos_weight': 2.5, 'learning_rate': 0.275, 'min_child_weight': 1.0, 'n_estimators': 285.0, 'subsample': 0.65, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 5.0, 'gamma': 0.65}\n",
      "{'status': 'ok', 'loss': 0.88659793814432986}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.6000000000000001, 'silent': 1, 'scale_pos_weight': 9.0, 'learning_rate': 0.125, 'min_child_weight': 3.0, 'n_estimators': 470.0, 'subsample': 0.8500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 3.0, 'gamma': 0.9500000000000001}\n",
      "{'status': 'ok', 'loss': 0.81468441391155011}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.6000000000000001, 'silent': 1, 'scale_pos_weight': 10.0, 'learning_rate': 0.025, 'min_child_weight': 4.0, 'n_estimators': 710.0, 'subsample': 0.9, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 3.0, 'gamma': 0.9500000000000001}\n",
      "{'status': 'ok', 'loss': 0.86863382512294729}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.55, 'silent': 1, 'scale_pos_weight': 9.0, 'learning_rate': 0.125, 'min_child_weight': 4.0, 'n_estimators': 475.0, 'subsample': 0.8500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 1.0, 'gamma': 1.0}\n",
      "{'status': 'ok', 'loss': 0.875}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.65, 'silent': 1, 'scale_pos_weight': 9.0, 'learning_rate': 0.5, 'min_child_weight': 3.0, 'n_estimators': 940.0, 'subsample': 0.9, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 2.0, 'gamma': 1.0}\n",
      "{'status': 'ok', 'loss': 0.84499128919860633}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.7000000000000001, 'silent': 1, 'scale_pos_weight': 7.5, 'learning_rate': 0.17500000000000002, 'min_child_weight': 6.0, 'n_estimators': 600.0, 'subsample': 1.0, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 3.0, 'gamma': 0.9500000000000001}\n",
      "{'status': 'ok', 'loss': 0.87300979140059598}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.6000000000000001, 'silent': 1, 'scale_pos_weight': 9.5, 'learning_rate': 0.07500000000000001, 'min_child_weight': 3.0, 'n_estimators': 720.0, 'subsample': 0.8, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 4.0, 'gamma': 0.9}\n",
      "{'status': 'ok', 'loss': 0.85004868549172341}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.5, 'silent': 1, 'scale_pos_weight': 8.5, 'learning_rate': 0.125, 'min_child_weight': 3.0, 'n_estimators': 225.0, 'subsample': 0.9500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 2.0, 'gamma': 0.8500000000000001}\n",
      "{'status': 'ok', 'loss': 0.91435282274976937}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.55, 'silent': 1, 'scale_pos_weight': 7.5, 'learning_rate': 0.4, 'min_child_weight': 4.0, 'n_estimators': 330.0, 'subsample': 0.8500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 3.0, 'gamma': 0.7000000000000001}\n",
      "{'status': 'ok', 'loss': 0.90540890269151142}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.8, 'silent': 1, 'scale_pos_weight': 8.5, 'learning_rate': 0.325, 'min_child_weight': 3.0, 'n_estimators': 110.0, 'subsample': 0.9, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 1.0, 'gamma': 0.65}\n",
      "{'status': 'ok', 'loss': 0.88231292517006799}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.7000000000000001, 'silent': 1, 'scale_pos_weight': 6.5, 'learning_rate': 0.05, 'min_child_weight': 6.0, 'n_estimators': 580.0, 'subsample': 0.75, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 5.0, 'gamma': 0.7000000000000001}\n",
      "{'status': 'ok', 'loss': 0.86240857712765961}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.6000000000000001, 'silent': 1, 'scale_pos_weight': 7.0, 'learning_rate': 0.2, 'min_child_weight': 5.0, 'n_estimators': 670.0, 'subsample': 0.9, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 4.0, 'gamma': 0.9}\n",
      "{'status': 'ok', 'loss': 0.87554713804713802}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.6000000000000001, 'silent': 1, 'scale_pos_weight': 0.5, 'learning_rate': 0.1, 'min_child_weight': 4.0, 'n_estimators': 500.0, 'subsample': 0.8, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 5.0, 'gamma': 0.55}\n",
      "{'status': 'ok', 'loss': 0.844763630089717}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.65, 'silent': 1, 'scale_pos_weight': 10.0, 'learning_rate': 0.47500000000000003, 'min_child_weight': 3.0, 'n_estimators': 760.0, 'subsample': 0.9500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 3.0, 'gamma': 1.0}\n",
      "{'status': 'ok', 'loss': 0.89867383201872231}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.55, 'silent': 1, 'scale_pos_weight': 6.0, 'learning_rate': 0.375, 'min_child_weight': 2.0, 'n_estimators': 415.0, 'subsample': 0.8500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 1.0, 'gamma': 0.75}\n",
      "{'status': 'ok', 'loss': 0.8179030252797348}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.5, 'silent': 1, 'scale_pos_weight': 5.5, 'learning_rate': 0.225, 'min_child_weight': 4.0, 'n_estimators': 895.0, 'subsample': 0.75, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 2.0, 'gamma': 0.9500000000000001}\n",
      "{'status': 'ok', 'loss': 0.87964808875790945}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.7000000000000001, 'silent': 1, 'scale_pos_weight': 9.5, 'learning_rate': 0.17500000000000002, 'min_child_weight': 2.0, 'n_estimators': 655.0, 'subsample': 1.0, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 4.0, 'gamma': 0.8500000000000001}\n",
      "{'status': 'ok', 'loss': 0.84084448160535108}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.75, 'silent': 1, 'scale_pos_weight': 8.0, 'learning_rate': 0.325, 'min_child_weight': 3.0, 'n_estimators': 525.0, 'subsample': 0.9500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 3.0, 'gamma': 0.6000000000000001}\n",
      "{'status': 'ok', 'loss': 0.87344720496894401}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.65, 'silent': 1, 'scale_pos_weight': 2.0, 'learning_rate': 0.45, 'min_child_weight': 5.0, 'n_estimators': 455.0, 'subsample': 0.8, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 6.0, 'gamma': 0.8}\n",
      "{'status': 'ok', 'loss': 0.87765338110165692}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 1.0, 'silent': 1, 'scale_pos_weight': 4.5, 'learning_rate': 0.325, 'min_child_weight': 4.0, 'n_estimators': 160.0, 'subsample': 0.7000000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 5.0, 'gamma': 0.9500000000000001}\n",
      "{'status': 'ok', 'loss': 0.84098432055749128}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.8, 'silent': 1, 'scale_pos_weight': 9.0, 'learning_rate': 0.1, 'min_child_weight': 2.0, 'n_estimators': 365.0, 'subsample': 0.9500000000000001, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 2.0, 'gamma': 0.55}\n",
      "{'status': 'ok', 'loss': 0.83278746569885809}\n",
      "Training with params : \n",
      "{'reg_alpha': 0.0, 'colsample_bytree': 0.6000000000000001, 'silent': 1, 'scale_pos_weight': 3.0, 'learning_rate': 0.225, 'min_child_weight': 1.0, 'n_estimators': 315.0, 'subsample': 0.9, 'reg_lambda': 1.0, 'objective': 'reg:linear', 'max_depth': 7.0, 'gamma': 0.9}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "\n",
    "# в этой функции мы проверяем, как ведёт себя модель при заданных параметрах\n",
    "def score(params):\n",
    "    print(\"Training with params : \")\n",
    "    print(params)\n",
    "    params['n_estimators'] = int(params['n_estimators'])\n",
    "    model = xgboost.XGBClassifier(**params)\n",
    "    aucs = []\n",
    "    # Для оценки качества используем KFold, который определили выше\n",
    "    for train_idx, test_idx in cv.split(X_train):\n",
    "        X_train_fold, X_test_fold = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
    "        y_train_fold, y_test_fold = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
    "        clf.fit(X_train_fold, y_train_fold)\n",
    "        preds = clf.predict_proba(X_test_fold)\n",
    "        auc = roc_auc_score(y_test_fold, preds[:, 1])\n",
    "        aucs.append(auc)\n",
    "    auc = np.mean(auc)\n",
    "    result = {'loss': auc, 'status': STATUS_OK}\n",
    "    print(result)\n",
    "    return result\n",
    "\n",
    "\n",
    "# это наша главная функция, в которой мы задаём параметры\n",
    "def optimize(trials):\n",
    "    space = {\n",
    "             'n_estimators' : hp.quniform('n_estimators', 100, 1000, 5), # (название параметра, от, до, шаг)\n",
    "             'learning_rate' : hp.quniform('learning_rate', 0.025, 0.5, 0.025),\n",
    "             'max_depth' : hp.quniform('max_depth', 1, 10, 1),\n",
    "             'min_child_weight' : hp.quniform('min_child_weight', 1, 6, 1),\n",
    "             'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma' : hp.quniform('gamma', 0.5, 1, 0.05),\n",
    "             'colsample_bytree' : hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "             'objective': 'reg:linear',\n",
    "             'silent' : 1,\n",
    "             'scale_pos_weight': hp.quniform('scale_pos_weight', 0.5, 10., 0.5),\n",
    "             'reg_alpha': 0.0,\n",
    "             'reg_lambda': 1.0\n",
    "             }\n",
    "\n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=250)\n",
    "    print('Best: ')\n",
    "    print(best)\n",
    "\n",
    "#сюда будет записана\n",
    "trials = Trials()\n",
    "\n",
    "optimize(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
